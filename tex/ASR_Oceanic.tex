%\documentclass[a4paper,10pt]{article} % Artikel med 12pt text och A4 storlek.
\documentclass[draft,10pt]{article} % Artikel med 12pt text och A4 storlek.
\usepackage[english]{babel} % Svensk avstavning istället för engelsk
%\usepackage[pdflatex]{graphicx}% De här två behövs för svenska
\usepackage[utf8]{inputenc} % UTF-8 encodad fil. Kan bytas ut mot latin1 om en vill...
\usepackage[T1]{fontenc}
\usepackage[authoryear]{natbib}
\usepackage{bibentry}
\usepackage{subcaption}
\usepackage{boldline} 
\usepackage{amsmath}
%\usepackage[allfiguresdraft]{draftfigure}
\usepackage{float}
\usepackage[margin=2.5cm]{geometry}
\usepackage{setspace}
\usepackage{color}
\usepackage{enumitem}   
\usepackage[T1]{tipa}
\usepackage{tabu}
\usepackage{textcomp}
\usepackage{rotating}
\usepackage{booktabs}
\renewcommand{\arraystretch}{1.3}
\usepackage{tabu}
\usepackage{longtable}
\usepackage{pbox}
\usepackage{setspace}
\usepackage{lscape}
%\usepackage{enumitem}
%\usepackage{enumerate}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{5}
\usepackage{array}
\newcolumntype{?}{!{\vrule width 1pt}}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
%\usepackage{graphics}
\usepackage{graphicx}
\usepackage{subcaption}

\usepackage{newfloat}
\DeclareFloatingEnvironment[placement={!ht},name=List]{mylist}


\usepackage{lipsum}

%chinese caracthers
\usepackage{CJKutf8}


\usepackage{footnote}
\usepackage{tipx}

\usepackage{wrapfig}
\usepackage[table,dvipsnames]{xcolor}
\usepackage{multirow}

\usepackage{titlesec}

\setcounter{secnumdepth}{4}


\usepackage{color}  
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=violet,  %choose some color if you want links to stand out
            urlcolor=blue,
            citecolor=Thistle,
}

\usepackage{xcolor}

\definecolor{spec_color_blue}{HTML}{7D81F5}
\definecolor{spec_color_lightgreen}{HTML}{81F093}
\definecolor{spec_color_darkgreen}{HTML}{0B8C1F}
\definecolor{spec_color_orange}{HTML}{FFB87A}
\definecolor{spec_color_red}{HTML}{FFD9E0}
\definecolor{spec_color_yellow}{HTML}{FCFFA8}



\setcitestyle{notesep={:},aysep={},aasep={\&}}
%\renewcommand{\labelitemi}{$\rightarrow$}
\usepackage{gb4e}

%\usepackage{draftwatermark}
%\SetWatermarkText{DRAFT}
%\SetWatermarkScale{4}

\pagestyle{myheadings}
\markright{\hfill \textcolor{red}{DRAFT}  \hfill Last update: \today \hfill} 


\noautomath
\title{Dissecting historical reconstruction: comparing computational approaches and the comparative method for Oceanic grammar}

\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex plus 0.5ex minus 0.2ex}

\begin{document}
\def\code#1{\texttt{#1}}

\thispagestyle{empty}
%\singlespacing

\maketitle
\thispagestyle{empty}

\tableofcontents
\newpage

%\textcolor{red}{This is a first draft based on the chapter text. I've modified it, and I'm in the process of modifying further. }



\begin{abstract}
Reconstruction is an essential part of historical linguistics.  The traditional Comparative Method (CM) identifies regular sound correspondences and cognates and then infers states in proto-languages by three core principles: assume the fewest changes on the tree, assume plausible changes, and assume plausible combinations of features in proto-languages. However, there is no clear consensus on how to weigh the principles against each other, and many studies are not fully transparent regarding how precisely the principles are applied. This allows for subjective differences between studies which are hard to discern and replicate.  This study aims to better understand the toolbox of historical linguistics in general and Oceanic grammatical history in particular by comparing the reconstruction of structural features by classical historical linguists to computational reconstructions with explicit and transparent mechanisms: Maximum Parsimony (MP) and Marginal Maximum Likelihood (ML). MP is similar to CM in that it infers the fewest amounts of changes along the tree.  ML on the other hand infers rates of change based on the distribution of values and takes into account branch lengths. In addition, we explore an even simpler method of reconstruction, which ignores tree structure and takes into account only the most common feature in the daughter languages. The results indicate that all methods applied achieve a high level of concordance with predictions from historical linguistics, which lets us understand the mechanisms of CM better. The more methodology is made explicit, the better we are off as a field.

% ste says: https://www.facebook.com/alan.elliott.125/posts/pfbid022H8vUKQxqKEE1e64DTcaJqXLDdruJEP8kpj5M89UtV6z8HHSTTTtYJVMVhZuBhsHl

%There are two possible
%This could indicate that historical linguists mainly make statements about the grammar of Oceanic proto-languages where they have a high amount of certainty, 

%The results show that CM produces reconstructions that are most similar to those generated by MP or MC. This suggests that, at least for this sample of languages and features, CM does not appear to take branch lengths into account. The methodological drawbacks of using MP and MC imply that we should possibly re-evaluate the way reconstruction is done in historical linguistics and take into account insights from new approaches, such as ML which makes sound assumptions which are likely to give better estimations of the state of proto-languages.


%Historical linguists use the comparative method to find sound correspondences, to reconstruct unattested forms and structures of proto-languages and to propose subgroups. Part of this process can be done computationally with new methods such as Maximal Likelihood. Such methods are more explicit in terms of the assumed underlying tree structure, data weighting etc. Studies in historical linguistics are not always as explicit. In this paper, we attempt to reconstruct the assumptions and implicit inner workings of the comparative method by comparing reconstructions made "by hand" by historical linguists to those derived from computational means. We also address areas of conflicts where different historical linguistics scholars disagree and evaluate what we can learn from computational methods regarding these issues. We estimate the grammatical structures of Oceanic languages in particular, using the Grambank dataset and trees published by Glottolog and \citet{grayetal_2009}. The results show that classical historical linguistics, for this dataset and trees, appears to mainly be an application of Maximum Parsimony, and we further discuss what this implies for the field of reconstruction of proto-languages. In the cases where historical linguists disagree, the results further shows that the most likely scenario is that proto-polynesian was ergative.
\end{abstract}
\newpage

\doublespacing
\section{Introduction}
\label{acr:intro}
Historical linguistic\footnote{
I am fortunate enough to have colleagues in academia who have been generous and helped me with technical matters and working through methodology conceptually, among these are: Stephen Mann, Angela Chira,  \begin{CJK*}{UTF8}{bsmi} 華夏\end{CJK*} Xià Huá, Cara Evans, Benedict King, Gerd Carling, Chundra Cathcart, Cristian Juárez, Viktor Martinović, Robert Tegethoff, Sandra Auderset and Hannah Haynie. I am also grateful to the two anonymous reviewers at Diachronica for their valuable feedback and to my PhD supervisors Andrew Pawley, Nicholas Evans, Mark Ellison and Simon Greenhill who also provided valuable commentary. Any mistakes and misconceptions that remain are my own.} offers us a unique and insightful window into our human past. By reconstructing the paths languages take, we can learn about our history and infer migration paths of people and cultures. By reconstructing the words and grammars of ancient languages, we can learn about communities long gone. Historical linguistics is devoted to this endeavour and has made great strides in our understanding of human history since its inception. The field has established methods which have enabled us to classify languages into language families and reconstruct words and sounds of proto-languages (unobserved ancestors of observed languages). Conclusions from historical linguistics are also impactful outside of linguistics, for example in archaeology and history studies. %ste says to insert ref

Scholars who work in historical linguistics produce valuable and greatly inspiring work and they possess a wealth of knowledge not only of the languages themselves, but also the cultures, societies and history of the region. At times, it is difficult to be explicit about all the background information and context that goes into analysis in historical linguistics --- which makes it hard for someone else to replicate.  In this study, we focus on one particular subset of the historical linguistics methodology --- the inference of earlier states given a particular tree and particular data --- and outline how computational methodology can be a complement which serves to increase transparency and consistency. The aim is to study the agreement between outcomes of conventional methods in historical linguistics and computational methods in order to increase the understanding of both approaches, and the see if there are any gains that can be made by effectivizing part of the process.

Historical linguists typically engage in three different tasks simultaneously: a) the identification of cognates and sound correspondences in languages, b) the inference of sub-grouping (networks/trees) and c) the inference of sounds/forms/patterns in proto-languages (Ancestral State Reconstruction = ASR). In conventional approaches in historical linguistics, these three tasks are done at the same time and inform each other --- they are necessarily interlinked. However, in historical analysis in biology and cultural evolution these tasks are often separated out. Fig. \ref{fig:HL_tasks} illustrates these three tasks for three different kinds of material: linguistic matter (sounds \& cognates), linguistic patterns (grammar) and biological traits. 

\begin{sidewaysfigure}[p]
\centering
\includegraphics[width=24cm]{illustrations/ASR_HL_explainer_ill.png}
\caption{The three tasks involved in historical reconstruction of linguistic matter (words \& sounds), patterns (grammar) and biological traits. Butterfly illustration is an image modified from \citet{savage2009single}.}
\label{fig:HL_tasks}
\end{sidewaysfigure}

The first row represents the typical historical linguistics study where the three tasks are components of one methodology --- the Comparative Method. The second row also features linguistic analysis, but of patterns (grammar) rather than matter. There is considerable debate within historical linguistics regarding if patterns can indeed be analysed with the Comparative method at all. The crucial difference between sounds and cognates one one hand and structural features on another that causes disagreements concerns the criteria whereby similarities are judge to be relevant for study. The Comparative Method, and historical linguistics methodology more broadly, is built on the recognition of the importance of cognates and sound correspondences --- two concepts which are difficult to translate into the world of morphology and syntax (see for example \citet{harris2008reconstruction} \& \citet{walkden_2013}). In order to establish shared inheritance, two languages need to exhibit pairs of words where the words themselves can with great certainty be said to related and where there is also a correspondence between the sounds within the words. This is what \citet{walkden_2013} calls the ``Double Cognacy Condition''. What does this mean for grammar? Are morphological patterns within sentences similar to sounds within words? The answer is not clear, and most likely differ depending on what kind of structural data we are dealing with (word order vs organisation of pronoun paradigms vs presence of certain markers etc). For this study, we will not delve too far into this debate but instead use a quantitative test of phylogenetic signal to estimate if the data is suitable for ASR (more on this below).

%Each of these tasks can be accomplished by different approaches. For example, historical linguists have certain criteria regarding what qualifies as relevant units to compare over (task a) and what ends up underlying the construction of the history (task b). In contrast, biologists use many different kinds of methods for Ancestral State Reconstruction: Maximal Likelihood, Stochastic Character Mapping etc (c.f. \cite{joy2016ancestral}), not to mention the variation in tree-constructing methodology. 

It is clear that the depth of knowledge possessed by historical linguists greatly informs their work, and that there is indeed value in linking these three tasks to each other (revise a tree when a reconstruction does not make sense, classify cognates of extant languages based on knowledge derived from elsewhere in the tree on how the changes can go etc). However, there are disadvantages as well; primary of these is the difficult in providing highly transparent methodology. This kind of labour involves a vast amount of knowledge and careful decisions, and it is not easy to make all of them explicit and accessible. In this particular study, we focus specifically on the task of ASR --- we are not deriving new trees or recoding the structural data at hand. In addition to increasing transparency, quantitative approaches to ASR also have the benefit of speed. If we can interrogate the conventional methods of ASR in historical linguistics and compare those principles to various computational approaches and evaluate the agreement, then we may be able to improve on the transparency of the method and offer historical linguists a convenient tool that can effectivize part of their labour.

%For the four proto-languages and structural traits considered here, 118 data-points are described in the classical historical linguistics literature (see \ref{sec:POC_lit_review}). In contrast, the computational approaches derived an additional 686 predictions about structural features of long-gone languages. 

In this study, we take a leaf out of the books of cultural evolution and biology. In these fields, the three tasks outlined above are separated out; appropriate data for analysis is collected (this can differ for tree/network construction and ASR) and trees\footnote{History of organisms and culture can be understood as trees, waves and networks. For the sake of space, we will write ``tree'' since this is most common but waves and networks are not excluded \emph{a priori}.} are constructed (usually with carefully chosen model approaches and priors). Once a reliable tree exists, ASR is carried out as a separate next step (c.f. \citet{holland2020accuracy} \& \citet{evans2021uses}). There is a smörgåsbord of methods that a scientists can choose to apply to each task. For example, you can use a plain distances based approach to making a tree \citep{jager2016inferring} or engage with more sophisticated Bayesian tools like BEAST \citep{drummond2015bayesian}. Similarly for ASR there are different approaches with different pros and cons (c.f. \cite{joy2016ancestral}). 

The input for ASR can differ from what was originally underlying the construction of the tree. If we believe that the tree is likely to be a good estimation of the history also for other data besides what it was directly based on, we may be able to carry out analysis with that tree on new different data. For example, \citet{watts2016ritual} analyze evolutionary dynamics of societal variables such as ritual human sacrifice and social stratification using a tree that is based on basic vocabulary and archaeological priors of island settlement. Besides arguing that it is reasonable to assume that the history of a communities cultural past is similar to its linguistic past, we can also test the strength of the phylogenetic signal statistically. If the data has a reasonable phylogenetic signal, we assumed that it is likely that it was generated by the tree and that we can proceed with further analysis. This is what \citet{watts2016ritual} did for their data, and they found that it was possible to carry out the analysis. We can do this as well for our trees and structural data.

Phylogenetic signal is the degree to which it can be assumed that a particular tree is likely to have given rise to the data in question. \footnote{Nota bene: this is not the same as stability/conservatism, phylogenetic signal is a separate concept.} There exists several different tests of phylogenetic signal, Pagel's $\lambda$ \citep{pagel1999inferring} and Bloomberg's K \citep{blomberg2003testing} being two of the better known. For binary data, the appropriate measure is \citet{fritz2010selectivity}'s \emph{D}-estimation. This method takes a tree and a binary trait (in this case structural features) and simulates what the distribution of values would be if the data was a) generated by Brownian evolution or b) randomly generated. The algorithm produces a D-estimate for each trait and tree, which represents the similarity to these two scenarios. If this value is 1 or higher, your data is similar to what would happen if the data was randomly generated and if it is 0 it is more similar to Brownian evolution. The algorithm also produces conventional p-values which show how likely it is that the data is dissimilar from 0 and dissimilar from 1. These conventional p-values are practical because they take into account sample size. 

In this study, we are primarily concerned with 84 unique Grambank features \footnote{For some proto-languages, we are interested in the same Grambank feature. The total amount of datapoints we are interested in for comparison to conventional historical linguistics is 118.} and three trees (Glottolog 4.4, Gray et al MCCT and an aggregate of 100 random trees in the Gray et al 2009 posterior). We carried out the D-estimate analysis on all of these features over all trees using the function phylo.d in the R package caper \citep{orme2013caper}. The results are summarised in table\ref{d_estimate_summary} (for more technical details, see Supplementary Material \ref{SM_d_estimate}). The second column of the table shows the mean D-estimate value over all relevant Grambank features for each phylogeny. The third column shows the percentage of features with p-values that indicate that they are similar to 0\footnote{Using the traditional cut-off of p > 0.05}. For the Gray et al 2009 MCCT and posterior sample, more than 60\% of the features are estimated to be similar to 0 --- i.e. have a credible phylogenetic signal. The values are less encouraging for the Glottolog-tree, this is most likely because it does not have branch lengths. The glottolog-tree will still be included because it is more similar to trees in traditional historical linguistics, and this is interesting here because it may mean it will generate results more similar to conventional historical linguistics --- but it should be noted that for quantitative analysis such trees are suboptimal . More details on the trees in this study is found in section \ref{the_trees}. The results from the D-estimate gives us confidence that we can proceed in general, but we will scrutinize the outcome of the features which are not similar to 0 in the results section.
 
 \input{"illustrations/plots_from_R//D-estimate_summary.tex"}
 
% the data that underlies the analysis does not necessarily meet the conditions of being cognate, the trees are estimated on a large amount of data and often also specific explicit priors about certain events, estimation of rates etc and the inference of ancestral forms can be (and often is) done separately. In this paper, we will only focus on the third of these task: the reconstruction of patterns in proto-languages or Ancestral State Reconstruction (henceforth ASR). The underlying data of the study is structural features in Grambank and we will use three existing trees --- we will not identifying cognates or estimate subgroups.

The fundamentals of ASR in traditional historical linguistics relies on three principles\footnote{It is also possible to include information on the history of particular regions and cultural factors, but this is less often made explicit.} (c.f. \citet{clark1973aspects}): 

\begin{mylist}
\begin{enumerate}[label=(\roman*)]
\label{HL_principles_asr}
\item the number of changes posited (as few as possible, also known as Maximum Parsimony)
\item the plausibility of the changes posited
\item the plausibility of the reconstructed language as a human language (i.e. the degree to which the reconstructed traits work well in harmony with each other)
\end{enumerate}
\caption{Principles of ASR in traditional historical linguistics}
\end{mylist}

As was highlighted earlier, ASR in historical linguistics is part of the overall toolbox of the Comparative Method, and as such is done simultaneously with the other two tasks. In this paper, we will be comparing specifically ASR of historical linguistics to computational approaches to ASR.

%The Comparative Method (CM) is a set of principles that can be applied to a set of languages and data to derive sub-groupings and ancestral states  This approach has yielded great results, such as the inference of many language families and proto-languages, and has robust control for avoiding trivial similarities.  In addition, historical linguists also apply a similar approach to the historical analysis of structural features such as morphology or syntax (e.g.\citet{harris2008reconstruction} \& \citet{walkden_2013}). Historical analysis of patterns (structural features) is less common and more controversial than the reconstruction of matter (sounds and words), primarily because it is difficult to apply the rigorous criteria whereby something is defined as a cognate to structural features \citep{walkden_2013}. This problem has led some scholars to label the enterprise Syntactic Reconstruction rather than incorporate the exercise as an application of the Comparative method \emph{per se}. In this paper, we will be comparing the reconstructions of patterns made by classical historical linguists to the outcomes of computational approaches to ASR that takes as its input abstract typological features. To make it clear that we are focussing specifically on ASR and not the Comparative Method overall we will use the term ASR throughout the paper.

One of the drawbacks of conventional  approaches to ASR in historical linguistics is that they typically involve a great deal of manual work and it can be difficult to be 100\% transparent with all analytical decisions --- in particular when it comes to what is judged to be a plausible change or a plausible combination of traits. In contrast, computational phylogenetic methods are a set of tools that can be applied with great speed and all analysis is explicit and consistent even over large amounts of data. Computational approaches are not intended to replace traditional historical linguistics, but rather they can function as a complement --- effectivizing parts of the process. In this paper, we examine how often computational methods of ASR arrive at the same conclusions as traditional historical linguists. We will also investigate what the computational methods say when historical linguists disagree, and make new predictions about the grammar of proto-languages.

%--- with some arguing that this cannot be included in CM at all.  Furthermore,  CM produces knowledge about relevant similarity between languages (regular sound correspondences and cognates),  proto-states and subgroupings but crucially \emph{not} branch lengths, inferences about specific migration paths etc. The methods that historical linguists use to derive this information, which is often necessary to make a language tree, is technically outside of CM ``proper''.  In this paper, we will not be creating any new trees but use existing ones. However we will use methods that take into account branch lengths and compare reconstructions of abstract grammatical features specifically.  The investigation goes beyond what might be called ``The Comparative Method Proper'' and concerns reconstruction in historical linguistics more generally. 

%\footnote{\citet[17-22]{clark1973aspects} is one of the more prominent instances of a historical linguists spelling out the principles underlying reconstruction in historical linguistics more generally, including syntactic reconstruction. However, 
%\citet{walkden_2013}
%} 

In recent years, linguists have begun to apply computational phylogenetic methods from biology to the reconstruction of linguistic history. Biologists have, similarly to linguists, been interested in inferring trees of the genetic relationship between species\footnote{Interestingly, the use of trees in linguistics and biology first occurred in publications just one year apart with \citet{schlegel1808sprache} publishing a tree of languages and \citet{lamarck1809philosophie} a tree of species. However, as \citet[370]{greenhill2015evolution} notes, it was not until Darwin's publication of \emph{The Origin of Species} in  \citeyear{darwin1859origin} that the concept of species trees in biology truly took off.}, ancestral states and the tempo and mode of evolution \citep{atkinson2005curious}. Biologists and linguists may have inspired each other, but methodologically the fields progressed separately for a long time \citep[370]{greenhill2015evolution}. Both fields are interested in answering similar questions: how are these languages/species related?, what was the earlier state of a language/species?, which traits are changing slower/faster? etc. The two fields have developed different methodologies, with biologists leaning more towards quantitative computational methods for tree construction and ASR compared to linguists who have on the other hand have developed a more rigorous tests for which data is valid for analysis (see the Double Cognacy Criteria in \citet{walkden_2013}).

Applying computational methods of ASR to linguistic data is becoming more common. \citet{jager2018using} apply three different methods (Maximum Parsimony, Maximum Likelihood and Minimal Lateral Networks) to cognate class reconstruction in three different language families. The aim of that study was primarily to evaluate how often the methods reconstructed the same state as what the authors label ``the Gold Standard'' (reconstructions by traditional historical linguists using the Comparative Method). This is similar to the study at hand, one of the aims of this paper is to estimate the degree of concurrence between computational methods using typological database data and conventional approaches in historical linguistics.The data that serves as input to the computational machinery in \citet{jager2018using} was annotated by ``hand'' for cognacy by historical linguists, meaning that the identification of cognate classes is still a human affair (task one in \ref{fig:HL_tasks}). This is also true for this study, the identification of structural features in languages is an entirely human process. Their overall result of \citet{jager2018using} was that Maximal Likelihood performed the most similar to traditional historical linguistics ASR, but that there were still several shortcomings.  Most notable of these are undetected borrowings, variation within languages and paralleled independent shifts.  In this paper, we address the potential for contact events by using sets of trees from a Bayesian posterior, some of which may represent an alternative contact history.

There are also two recent studies of Indo-European grammatical history: \citet{carling2021reconstructing} and \citet{goldstein_2022}. \citet{carling2021reconstructing} evaluate different theories of the history of morphosyntax of Indo-European by comparing to the product of computational Bayesian phylogenetic modelling. They find support for the ``canonical'' model of Indo-European syntax and illustrate clearly with case examples how their model works. Goldstein in his paper challenges a commonly applied principle in the reconstruction of Indo-European syntax; the ``frequency heuristic'' which holds that \emph{if the number of homologous elements (e.g., lexical cognates) in the daughter languages meets a minimum threshold (canonically three), their ancestor is reconstructed to the root of the tree}\citep[1/71]{goldstein_2022}. This is done because scholars argue that the true tree is unknown, and that this is an appropriate method in the absence of the true tree. Goldstein argues that the appropriate action is instead to carry out reconstruction on many different trees that represent possible histories --- a Bayesian posterior tree sample. He argues that this is methodologically more sound and because the results of his approach are in accord with the consensus in historical linguistics it strengths their validity.

Both \citet{carling2021reconstructing} and \citet{goldstein_2022} use a Bayesian method of ASR known as Continuous-Time Markov Chain (CTMC)\footnote{The main difference between the methods of \citet{carling2021reconstructing} and \citet{goldstein_2022} is that \citet{carling2021reconstructing} use a tree structure informed by \citet{chang2015ancestry} and comparative-historical \emph{communis opinio} and vary the branch lengths 10,0000 times in a principled and informed manner to generate 10,000 different trees while \citet{goldstein_2022} takes 100 random samples directly from the posterior of \citet{chang2015ancestry}.}. This approach comes with certain important assumptions, to quote from \citet[77]{goldstein_2022}:

\begin{quotation} \emph{
CTMCs model language change as a stochastic phenomenon with rate parameters that govern the amount of time between transition events. It is worth highlighting the assumptions that these models bring with them. First, character states at the nodes of a tree are assumed to depend only on the state of their immediate ancestors and the length of the branch along which they evolved (Cathcart 2018:4). Second, the probability of a transition depends only on the current state of a language. Its previous history is irrelevant. This is known as the markov property. Finally, rates of gain and loss are assumed not to vary across the tree.}
\end{quotation}

It is always important to be up-front and explicit about the assumptions an approach takes and evaluate if they make sense for the given situation. For linguistic data, these assumptions do seem to hold. For more details on the methods, please see  \citet{goldstein_2022}, \citet{pagel2004bayesian}, \citet{ronquist2004bayesian} and \citet{liggett2010continuous}\footnote{Another popular method of ancestral state reconstruction is Stochastic Character Mapping \citep{huelsenbeck2003stochastic}. SCM is a procedure that can follow the same the CTMC approach employed by \citet{carling2021reconstructing} and \citet{goldstein_2022}, but not necessarily.  SCM is a procedure that simulates character histories using Continuous Time Markov-rates. These rates are usually estimated on the basis of the tree topology and the data attested at tree tips before SCM is carried out, but can also be defined in other ways. Thank you to one of the anonymous reviewers for highlighting this. }.

%reviewer 2: This statement is imprecise. SCM is a procedure that simulates character histories using CTM rates. These rates are usually estimated on the basis of the tree topology and the data attested at tree tips before SCM is carried out. So SCM is a procedure that can follow the method described by Goldstein (but can also be used with arbitrarily defined rates).

Computational approaches to reconstruction not only allow us to effectivize the process by inferring the prior states of hundreds of traits in a short span of time, but they also allows us to apply exactly the same principles in exactly the same way to all pieces of data. This is much harder to do manually, since different scholars may use slightly different assumptions and judgement when applying the traditional Comparative Method. One could say that what we loose in deep human insight, we gain in consistency and speed. Furthermore, if the deep human insight that historical linguistics has benefited so much from could be quantified into priors that can be fed into computational models --- we may not need to loose anything! Unfortunately this is not the case currently, but it may be possible in the future.
%Any assumptions about plausibility of changes or states needs to be explicitly included into the model, and applied identically across the sample.

The particular study object of this paper is the Oceanic language subgroup of the Austronesian family and the grammatical features of four of its proto-languages. We use information about the extant daughter languages from the Grambank dataset \citep{skirgaard2022grambank_preprint} to infer the structure of proto-languages given three trees: a) Glottolog 4.0, b)\citet{grayetal_2009} - MCCT and c) \citet{grayetal_2009} - posteriors aggregate (see more in section \ref{the_trees}). Findings from the historical linguistics literature have been translated into data-points in the Grambank format for four specific proto-languages: Proto-Oceanic, Proto-Central Pacific\footnote{The concept of Proto-Central Pacific as a coherent subgroup is not uncontroversial.  \citet{grace1958position} and \citet{pawley1972internal} made a case for a subgroup consisting of Fijian, Polynesian and Rotuman. Later \citet{geraghty1996} shows that the evidence for this stage is limited.  We will be using it here in this study because it occurs enough frequently in the literature, but readers should be aware that it is less likely to have been a genuine coherent language of a community compared to the others. Thank you to Andrew Pawley for drawing this to my attention.}, Proto-Polynesian and Proto-Eastern Polynesian. The computational methods take as input the language-level data points in the Oceanic subgroups and then infer grammatical states of proto-languages in the tree. The structural features of the four proto-languages are extracted for each tree and method and compared to conclusions from classical historical linguistics. The results are evaluated in terms of concordance between each method and the predictions from classical historical linguistics. We are evaluating how much they agree, not necessarily which one is correct. Which method is correct should be estimated based on the conceptual underpinnings and assumptions of the method and how plausible that model of change is. Both traditional methods of ASR in historical linguistics and the particular computational approaches in this paper have advantages and disadvantages. Much of the conceptual infrastructure is similar, which is why we would assume a high degree of concurrence between the methods. 

From the exercise in this study we can learn about which method agrees most with classical historical linguistics, and therefore dissect the comparative method into explicitly formally objectively defined mechanisms.

There is one area of Oceanic grammatical reconstruction where there is considerable disagreement. This concerns the nature of the alignment system of Proto-Polynesian and Proto-Central Pacific. These issues will be investigated and evaluated separately from the overall results of how much agreement there is between classical historical linguistics and the computational approaches.

Finally, this study also yields predictions about grammatical features of the four proto-languages that were not addressed by the historical linguistics studies surveyed here.

%The tools of computational reconstructions are different from classical historical linguistics, and the data used in this chapter, the Grambank dataset, is different from the source material that historical linguists work with. This is further discussed in section \ref{sec:ars:metod:hist}


\section{Background}
\label{recon_grammar}

f\subsection{The methods of traditional historical linguistics: the Comparative Method}
\label{sec:ars:metod:hist}
In order to interpret the differences between the results of the computational approach versus the classical historical linguistics approach, it is first necessary to clarify the different methodologies and the consequences of them for the study at hand. This section lays out the fundamental principles of historical linguistics and how they relate to this paper.

The core method by which historical linguists reconstruct language history generally is known as the ``Comparative Method''. The Comparative Method is based on finding words or morphemes in different languages that have the same (or similar enough) meaning and that display non-trivial systematic phonological similarities. By investigating these sets of words, it is possible to deduce which are inherited from a common shared ancestor, i.e. are cognates. For example, \citet{blust2004}, \citet{greenhill2011pollex} and many others have reconstructed that M\={a}ori /toru/ (meaning `three') derives from the same word in an ancestral language as Hawai'ian /kolu/ (`three') does. These two words are ``cognates'' of each other and this information can be used to reconstruct a form for proto-Polynesian. Furthermore, many words that mean the same/similar thing in M\={a}ori and Hawai'ian show this pattern of t/k, e.g. M\={a}ori: /mate/, Hawai'ian: /make/ `to be dead'  and M\={a}ori: /whitu/, Hawai'ian: /hiku/ `seven' \citep{ABVD}. There is a systematic correspondence between these two sounds; regularly when there is a /t/ in M\={a}ori there is a /k/ in the corresponding position in Hawai'ian\footnote{Further research into more languages of this family shows that Hawai'ian /k/ is more likely to be an innovation and M\={a}ori /t/ a retention from an older proto-language (c.f. in the Austronesian language Amis of Taiwan `three' is /tulu/). Therefore, we can reconstruct that the change went from /t/ $\rightarrow$ /k/.}. This is known as a \emph{systematic sound correspondence}. One crucial part of this approach is what \citet{walkden_2013} calls the ``Double Cognacy Criterion'' which states that both the part --- the sound --- and the context it occurs in --- the word --- need to be cognate in order to form valid data for reconstruction and sub-grouping. This condition of the Comparative Method is often more difficult to apply when reconstructing structural features, which is why some scholars use a different label for reconstruction of such material --- most commonly Syntactic Reconstruction \citep[17]{clark1973aspects}\footnote{Note that the term ``Syntactic Reconstruction'' is used for reconstruction of both morphology and syntax.}.

% \citep{ABVD})\footnote{Note that there are two /k/ sounds in Oceanic languages. One stems from Proto-Oceanic *t and the other from POC *k. See more details in \citet{blust2004}.}. 

As we saw in the introduction, the Comparative Method is used both for developing hypotheses about forms in unobserved proto-languages and proposing sub-groupings based on shared innovations (c.f. how biological cladistics finds relationships between species based on shared derived characteristics from common ancestors \citep[16-17]{maclaurin2008biodiversity}). The Comparative Method provides us with a) sets of words which derive from the same word in an ancestor language (cognates), b) sequences of sound changes from proto-languages to the current observable daughter languages and c) a tree or network structure of the relationships between languages. 
 
The processes of subgrouping and ASR are done in tandem in historical linguistics; they are estimated simultaneously. Subgroups are proposed based on \textbf{shared innovations}. In order to determine what is and what is not an innovation, a certain amount of reconstruction of proto-languages words and sounds (ASR) is necessary. In order to do ASR, some of the tree structure needs to be approximated\footnote{Pawley (personal correspondence) notes that most of the subgrouping done in historical linguistics tends to be at the lower level.}. This is different from analysis in biology and cultural evolution where ASR is carried out as a separate next step after a reliable model of history is constructed (c.f. \citet{holland2020accuracy} \& \citet{evans2021uses}). In this paper, we are comparing specifically ASR results, not subgrouping. Thankfully, this feedback loop between ASR and subgrouping is primarily a factor in the analysis of linguistic matter (sounds and words) --- and less relevant for linguistic patterns (structural features) which is the topic of this paper.

% The computational approaches to reconstruction applied in this paper are only concerned with ASR, not subgrouping.  We are using existing trees as input, these are not estimated in themselves. 

%This is one of several differences between the computational reconstruction methods and conventional approaches in classical historical linguistics.
%we are only focussing on the reconstruction --- not on the identification of regular sound correspondences, cognates or subgroups. 


%list the reconstruction */gaawari/ for Proto-Polynesian as meaning `weak, feeble'. In some of the daughter languages, words deriving from this Proto-word are listed as meaning `bent', `weak', `soft' and `slack (of man)'. These meanings are judged to be plausible semantic extensions of the proto-meaning such that they can be said to be related ---- to be cognates. 

%\footnote{In order to estimate what semantic shifts are reasonable, linguists can study colexifications in contemporary languages. These are instances of different meanings that are expressed by the same word. In the Database of Cross-Linguistic Colexifications (CLICS), users can explore clusters of colexifications, for example: the concept ``sun'' is more closely linked to ``day (not night)'' than it is linked to ``name'' ) \cite{list2018clics2}.}

Historical linguistics has been primarily concerned with the reconstruction of sounds and words, but there is also work on the reconstruction of grammatical features such as morphemes or word order. \citet[17-22]{clark1973aspects} wrote about Proto-Polynesian syntax for example and outlined general principles for ASR in traditional historical linguistics that can also be applied to structural data (see list \ref{HL_principles_asr} in section \ref{acr:intro}.

%\begin{enumerate}[label=(\roman*)]
%\item the number of changes posited
%\item the plausibility of the changes posited
%\item the plausibility of the reconstructed language as a human language (i.e. the degree to which the reconstructed traits work well in harmony with each other)
%\end{enumerate}

The first of these principles (``fewest amount of changes'') is the same as what is known in phylogenetics as ``Maximum Parsimony'' \citet{felsenstein2004inferring}. The idea is to reconstruct states in proto-languages such that there are as few changes as possible between nodes in the entire tree. \citet[17-22]{clark1973aspects} explains how this works by positing an example of seven languages where there is a majority of one kind of value, X, and fewer of another, Y. Fig.~\ref{fig:clark_tree} illustrates this example. If we only examine which feature is the most common, we should reconstruct X at the root of this tree (this is what \cite{goldstein_2022} calls the frequency heuristic). However, this candidate solution would result in two changes (one each between the root and tips A and B). If we instead reconstruct Y at the root, we would only need one change (between the root and PC-G). The solution where we reconstruct Y at the root results in fewer changes --- it is the most parsimonious --- and is therefore preferred candidate.
 
\begin{figure}[h]
\centering
\includegraphics[width=8cm]{illustrations/Clark_1977_tree.png}
\caption{{Tree from \citet[19]{clark1973aspects} illustrating Maximum Parsimony.}}
\label{fig:clark_tree}
\end{figure}

It is important to note that Maximum Parsimony does not take into account the length of branches, only the changes between each node of the tree (regardless of how far apart they are). Furthermore, the solution that Maximum Parsimony selects is the candidate solution with the fewest changes (also known as  ``lowest Parsimony cost''). If we think of rate of change as number of changes per branch, then Maximum Parsimony selects the candidate solution with the slowest rate out of all possible solutions it can choose from. This may be incorrect, it is possible that the true solution is not the slowest. Maximal Likelihood (and other more sophisticated ASR-methods) improve upon this by taking branch lengths into account and actively estimating likely asymmetric rates (1$rightarrow$0 can be different from 0$rightarrow$1) and actively applying the most likely rate to the inference of unknown ancestral states. ML attempts to find the most likely solution, MP can be said to find the solution with the slowest rate\footnote{It should be noted that my use here of ``rate of change'' in relation to Maximum Parsimony (changes per branch) is not directly comparable to rates of change estimated by other methods, such as ML. MP does not technically estimate a rate of change at all and does not model branches in a meaningful way, it is only concerned with changes between nodes. MP can however be said to \emph{assume} the slowest rate of change, given the definition of rate as changes per branch.}.

The next principle of ASR in historical linguistics concern plausibility of changes --- phonological, semantic and grammatical. For example, many historical linguists posit that /s/ is more likely to become /h/ than it is to become a /k/\footnote{Historical linguists do concede that there are instances of irregular sound change \citep{blust1996neogrammarian, campbell1996sound} and that while they can often be explained by contact, analogy or avoidance of homophony, they sometimes remain unexplained.}.  In the above example from M\={a}ori and Hawai'ian, the words /toru/ and /kolu/ both mean `three', but it is possible for cognates to have less similar meanings. For example, \citet{pawley2005meaning} reconstructs the proto-form *\emph{panua} as meaning `land' or `inhabited territory'. In daughter languages, this has changed to `place', `community', `village', `house', `people', `world' and `weather'. These are related meanings, but not identical. Historical linguists aim to have plausible semantic connections between words that are proposed to stem from the same proto-form, they cannot be too dissimilar. This is difficult, as can be seen from this quote from \citet[229]{anttila1989historical}:``there are no exact rules for handling semantic change; the final factor here is necessarily the common sense and the experience of the individual scholar''. Finally, plausibility of changes also comes into play when reconstructing structural traits. For example, a language going from having no marked dual number on nouns to having trial number would be taken as unusual by most linguists \citep[c.f.][8]{kikusawa_2006_pro_number}. It is more expected that a language acquires marking of dual as a necessary step before marking trial. Grammaticalization theories have given rise to a number of these plausible changes \citep[594-5, 598]{heine2003grammaticalization}.

Lastly ASR in historical linguistics deals with the plausibility of the whole of the reconstructed proto-language as a system \citep[1]{clark1973aspects}. For example, if we reconstruct a language with very uncommon combinations of features we should be wary and probably question ourselves. This is more relevant for phonology and structure where we have more worked out theories of plausible combinations than in the lexicon.

%. We cannot compare Parsimony cost directly to rate of change estimated by other models, but out of all the possible solutions Maximum Likelihood generates it does not necessarily select the one with the slowest rate of change  (more on this in section \ref{sec:asr_methods}).

The procedure of ASR in historical linguistics that has been outlined in this section can and has been applied successfully to sounds and words (be they lexical or grammatical words).  The application of this approach to abstract structural features is more controversial, and is not always included under a more strict application of the term ``Comparative Method''. Some scholars even state ASR of structural features is impossible \citep[c.f]{lightfoot_2002b}. One of the concerns is whether the underlying data represents genuine correspondences (for example by satisfying the Double Cognacy Condition as described by \citet{walkden_2013}). \citet{walkden_2013}) explores the possibility of successful reconstruction of a structural feature and outlines that one possible approach is to break down structural patterns/item into definitional features (similar to phonological features) and consider syntactical context as similar to phonological context (words). For this study, we are using Grambank features which are accompanied by coding documentation that shares certain similarity to the features Walkden describes...

<insert more on walkdens similarities to \citet{traugott2003constructions} and\citet{heine2003grammaticalization} >

%##HELP NEEDED juarez viktor

While it is true that reconstruction of structural features is not the same as reconstruction of lexical items and sounds, several scholars have found that it is achievable. Most of the discussion of particular reconstructions and theoretical matters have been in relation to Indo-European languages. In this paper, we turn to the traditions and achievements in Oceanic linguistics in particular. We can be heartened by several publications on the reconstruction of grammatical features in Oceanic (see section \ref{sec:POC_lit_review}), but we can also substantiate the validity of this enterprise by investigating the phylogenetic signal of Grambank features.  Grambank features are binary, and therefore we use the D-estimate approach from \citet{fritz2010selectivity} to estimate phylogenetic signal. If there is phylogenetic signal in Grambank data for Oceanic languages, that is an indication that reconstruction can be fruitful. D-estimates are singular numbers, if they are close to 0 then the given feature behaves similar to Brownian evolution, if it is closer to 1 it is more similar to random evolution (no phylogenetic signal). Values can also be higher than 1 (overdispersed) and lower than 0 (more conserved than Brownian evolution). See Supplementary Section [hedvig to insert ref] for more tehnical details on D-estimates. For this study, we use 3 different trees: Glottolog, Gray et al 2009-MCCT and an average over 100 randomly selected posterior trees of Gray et al 2009. The table below shows the average D-estimate for all features per tree. The D-estimate test also determines a p-value of how different the D-estimate is to 0, the third column in the table shows the proportions of features per tree that are similar to 0 (given a cut-off of p> 0.05). For the Glottolog tree, the majority of the features are different from 0 but for the other two the majority are similar. This gives us an indication that the latter two trees are more reliable and that reconstruction with them is possible. This study will still incorporate the Glottolog-tree because it is more similar to the topologies of conventional historical linguistics --- but note this discrepancy.

%harris2008reconstruction


%tree	D-estimate (mean)	Propotion of features signficantly similar to 0
%glottolog	0.52	0.36
%gray_mcct	0.46	0.60
%gray_posterior	0.23	0.77


%As a consequence of that, it can be said that not all reconstruction in historical linguistics is based on the Comparative Method in a strict sense. . Some of the work on reconstruction in historical linguistics cited in this paper can be said to represent \emph{traditional approaches}, but perhaps not necessarily the \emph{Comparative Method} in a strict sense.

{\color{red}This section and section \ref{diff_lexi_str} are being re-written to more clearly tease out and discuss details of reconstruction of abstract structural features.}

%The plausibility of the reconstruction language to be a human language relies on knowledge about which traits are likely to go together, and which would represent a combination that is veyr implausible. For example, if a language has a dual number category for nouns, i.e. signalling that the number of items is 2, it is likely to also have general plural number. If a reconstruction produces a language with a dual but not a plural, this is cause for concern as this is very unlikely according to linguists. The same is true of the plausibility of the changes from state to state themselves, some changes are assumed to be more frequent and common than others. However, linguists rarely spell out all of these assumptions explicitly in historical reconstruction, which makes it hard to evaluate what is happening. It also makes it difficult to incorporate these concepts in computational reconstruction. 

%Integral to the reconstruction of forms in historical linguistics is \textbf{Maximum Parsimony}. Maximum Parsimony is a method of reconstruction ancestral states (in this case grammatical features of proto-languages) in such a way that there is as few changes as possible from the root to every tip (language). 


\subsubsection{Disagreements in historical linguistics}
Reconstruction in historical linguistics includes judgements of plausibility.  This  requires some assumptions about what are plausible features to co-occur in language, and which pathways of language change are more plausible than others. For example, it is rare to find a language that has a gender distinction in first person, but not in third (though not impossible; c.f. \citet{wals-44}). If the most parsimonious reconstruction results in a proto-language with many rare features or unusual combinations of features, it may require reconsideration. If something is rare in the languages that exist today, we would expect it to be rare also in past languages. Similarly, changes from certain states to others are assumed to be less plausible. For example, a language going from having no marked dual number on nouns to having trial number would be taken as unusual by most linguists \citep[c.f.][8]{kikusawa_2006_pro_number}. 

Plausibility is important in reconstruction, both in linguistics and in biology. However, this principle is sensitive to differing assumptions and theories. What is more plausible as a reconstructed language or species may differ from scholar to scholar. Besides debates over precise sub-groupings, many arguments in historical linguistics boil down to disagreements about plausibility. This is also true of the different reconstructions of the alignment system of Proto-Polynesian.

\citet{clark1973aspects} disagrees with \citet{hale_1968}, \citet{hohepa_1969}, and \citet{chung1978} on the state of Proto-Polynesian syntax on these grounds. Chung, Hale and Hohepa argue for a theory that is technically less parsimonious, but which they say is more plausible. They posit that Proto-Polynesian had a nominative-accusative case marking system\footnote{Hale, Hohepa and Chung actually suggest three different specific theories for this reconstruction. For a summary of the differences between the proposals, see \citet[247-249]{chung1978}.}. If this was the case, that would mean positing more changes along the tree than if we assumed, as \citet{clark1973aspects} does, that the Proto-Polynesian language was ergative-absolutive. This is due to S\={a}moan and Tongan both having ergative-absolutive marking and both splitting off early (in most accounts of the Polynesian tree) from Proto-Polynesian compared to the rest of the group which most often lacks ergative-absolutive marking. Fig. \ref{poly_GB409_tree} shows the Polynesian tree with Grambank feature GB409 values marked out\footnote{Grambank feature GB409 asks if \emph{any} ergative flagging is present. In some instances, the system is not wholly or primarily ergative, but ergative marking is present. It is possible that the scholars involved in the debate would not classify such languages as ``ergative-absolute'' languages.}.

\begin{figure}[H]
\centering
\includegraphics[width=9cm]{illustrations/plots_from_R//tree_plots/poly_tree_example.png}
\caption{{The Polynesian languages in the \citet{grayetal_2009} Maximum Clade Credibility Tree-tree, with the coding of Grambank feature GB409 ``Is there any ergative alignment of flagging?'' marked out. Purple = Yes, Yellow = No and white = Not enough information/not clear.}}
\label{poly_GB409_tree}
\end{figure} 

Chung's critique of Clark's proposal is three-fold: 
\begin{enumerate}[label=(\alph*)]
\item the tree used is not an accurate representation of the language history (there was more interaction between S\={a}moan and Tongan after splitting, i.e. horizontal transfer)
\item it is possible that the Proto-language contained variation and was undergoing change that was only fully realised in some of the daughters
\item the morpho-syntactical historical process itself is less plausible
\end{enumerate}

In a review of \citet{clark1973aspects}, Chung writes:

\begin{quotation}
\noindent\emph{Such an approach [as Clark's] relies on the assumption that the subgroups have developed quite independently once they split off from Proto-Polynesian, so that features shared by both must be attributed to the Proto-language. But in fact, both parts of this assumption are too strong. It is well known that the two primary subgroups of Polynesian did not develop totally separately; there was long-standing contact in pre-European times between speakers of Tongic and some Samoic-Outlier languages, as Clark himself notes (p. 27). Further, and more generally, it is simply not true that every feature shared by related languages must have existed in the Proto-language uniting them. Languages are constantly undergoing change; and it is reasonable to suppose that Proto-languages were no different from real languages in this respect. But if this is so, then it is also reasonable that changes begun in a Proto-language may have continued even after its separation into daughter languages. In this way, related languages may come to share a feature which existed only in embryonic form, or not at all, in their common ancestor.}
\end{quotation}
\begin{flushright} \citet[539]{chung1977aspects}  \end{flushright}

This debate contains more twists and turns, with each side arguing for the plausibility of their accounts. In our analysis, we will be using trees that represents the history of the languages in a similar way to Clark, which means the results are sensitive to the same critique by Chung (i.e. not taking into account horizontal transfer between S\={a}moan and Tongan). We are also not able to use plausibility in our computational reconstructions since we do not have access to formalised data on what plausible language profiles or changes are. This is a key difference between computational reconstruction and traditional approaches to reconstruction. Knowledge of plausibility and how to weigh different kinds of evidence against each other is not formalised and therefore cannot be taken into account.

%It is possible that with the added information on rates of change and branch length that comes with the Maximum Likelihood approach we are able to approximate some parts of historical linguists' knowledge of plausibility. In that case, we would expect the Maximum Likelihood results to concur more with the predictions by expert linguists. If historical linguists mainly do operate on the same principles of Maximum Parsimony, and/or Maximum Likelihood is not able to approximate plausibility, we would expect the results of Maximum Parsimony to concur more with findings in traditional historical linguistics.

In this study, any instances of conflicting data from historical linguists concerning proto-languages are evaluated separately from the overall results and will be reported in a separate section. There are three instances of this: two features related to the alignment of Proto-Polynesian (GB408 Is there any accusative alignment of flagging? and GB409: Is there any ergative alignment of flagging?) and one feature for Proto-Central Pacific, where \citet{kikusawa2002proto} and \citet{ball2007ergativity} disagree on the alignment as well.

%can fall short of reconstructions carried out by classical historical linguists because they are able to take these plausibility considerations into account.

%\subsubsection{Reconstruction and subgrouping in tandem}
%The processes of subgrouping and reconstruction are done in tandem in historical linguistics; they are estimated simultaneously. Subgroups are proposed based on shared innovations. In order to determine what is and what is not an innovation, a certain amount of reconstruction is necessary. In order to make reconstructions, some of the tree structure needs to be approximated. Pawley (personal correspondence) notes that most of the subgrouping done in historical linguistics tends to be at the lower level. 
%This can be seen later in this paper in the difference between the Glottolog tree (Fig. \ref{tree_coverage_oceanic_glottolog}), which is based on classical historical linguistics,  and the Gray et al 2009-tree (Fig. \ref{tree_coverage_oceanic_gray}), which is inferred with Bayesian phylogenetic methods using basic vocabulary data. Most of the splits in the Glottolog tree occur close to the tips, whereas the splits are more spread out over the distance between the root and the tips in the Gray et al 2009-tree.

%Besides parsimony and plausibility, it is also important to know how to weight evidence when conducting historical linguistics research, in particular when it comes to subgrouping. This is less often discussed explicitly, but it is related to issues of plausibility and is likewise a source of disagreement. It is for example possible that certain data-points are more susceptible to contact-induced change than others, and should therefore carry less weight if we are trying to infer a family tree. This is why items and features that are thought to be particularly stable and unlikely to be borrowed are used in reconstruction and subgrouping \citep[c.f.][]{pawley_2009_solomons}.

%In this paper we are not proposing any new subgroupings, so the problem of weighting evidence is not present in this manner. For the reconstruction of grammatical features, all languages are weighted as equally valuable and we use the tree topologies directly to control for non-independence of datapoints as opposed to careful sampling \citep[c.f.][]{ross2004morphosyntactic}.
%We are reconstructing grammatical features and this is another area where weighting can be relevant. All languages are weighted the same for the reconstruction, but 

%As was discussed in \ref{sec:dep}, not all data-points are independent of each other and this may be one reason to weight them differently. 

%For example, \citet{wilson_whence} presents a case for Eastern Polynesia (EP) being settled from the so-called ``Northern Outliers'' (i.e. Polynesian languages of Micronesia and the Solomons) by demonstrating shared innovations of lexicon and grammar to the exclusion of Samoa, Pukapuka and Tokelau (which were closer to EP in previous proposals). The paper lays out 73 innovations in support for this theory, and states that there is a lack of shared innovations supporting grouping Eastern Polynesia and the Samoic group together, as had been previously suggested by \citet{pawley1966polynesian}. \citet{wilson_whence} proposes that a more accurate reflection of this data is to group Eastern Polynesian with the Northern Outliers. On the other hand, \citet[53, 61]{pawley1966polynesian} presents two cases where Samoan and some of the Northern outliers shared features to the exclusion of Eastern Polynesia (sing/plural distinctions in indefinite articles and the form of the human number prefix). Besides the sheer number of data-points, it is clear that historical linguists also weight different pieces of information differently. Without an internalised in-depth knowledge of these matters, it is difficult to know how to evaluate the support for these conflicting theories of the origins of Eastern Polynesian communities. Is it as significant that the Northern Outliers and Eastern Polynesian languages shared a word for a certain kind of fish (\emph{*kamakama}) as the fact that they have also, as a group, added an \emph{o-} to the Proto-Polynesian root \emph{*fia} (want) \citep{wilson_whence}? 

%In this paper we are not proposing any new subgroupings, so the problem of weighting evidence is not present in this manner. We are, however, reconstructing grammatical features and this is another area where weighting can be relevant. All languages are weighted the same for the reconstruction, but 

%The tree structure and the method (Maximum Parsimony or Maximum Likelihood) determines the reconstruction. This can be compared to weighting evidence from oversampled areas/subgroups less when reconstructing. 

% \citet[135]{marck2000} also presents the case that the Northern Outliers are most closely related to Tuvaluan.

%It is clear that considerable experience and meticulous considerations are needed in order to make these judgements and interpret the results of these papers appropriately. This entails long periods of training and familiarisation with the method in practice and the particular languages in question. \citet[721-731]{blust2013austronesian} suggests that we should bring in non-linguistic evidence to bear on these theories as well. How would a settlement from the Northern Outliers be achieved materially? By finding supporting or conflicting evidence from other disciplines, we can make more robust predictions 

%For full disclosure, both of the trees used in this study (Glottolog 4.0 and \citet{grayetal_2009}) group EP closer to the Northern Outliers than to Samoan, and it is becoming more accepted. 


\subsection{Characteristics of language structure as data}
\label{diff_lexi_str}

{\color{red}This section is being re-written to more clearly tease out and discuss details of reconstruction of abstract structural features. c.f. \cite{walkden_2013}}.

The Comparative Method is most often applied to lexical words and sounds, but it can also be applied to grammatical morphemes and features. \citet{crowley1985common} for example traces the history of a common noun phrase marker \emph{*na/*a} in Oceanic languages using the Comparative Method. (c.f. also the case studies of \citet{goldstein_2022}). 

The data in this paper does not track specific forms, as is common when reconstructing proto-languages in historical linguistics (c.f \citet{pawley1973some, crowley1985common, evans2003study}). Instead we use binary features of a typological questionnaire which tracks a large part of ``core" grammar --- the Grambank dataset. (c.f. \citet{carling2021reconstructing}) This section outlines some crucial differences between structural data and the kind of data that is typically used in historical linguistics in relation to the present study.

The kind of data used in grammatical reconstruction in historical linguistics differs from what we find in linguistic typological questionnaires such as Grambank. \citet{crowley1985common}, \citet{clark1973aspects}, and other scholars whose work we will compare to our results in this paper, typically apply the comparative method to specific formal expressions of structural features (the \emph{na} article, \emph{-Cia} suffix, \emph{faka-} prefix etc). They take into account fossilised forms (the common noun marker \emph{-a} fusing to roots in Paamese \citep[141]{crowley1985common}) and related meanings (the hypothesis of \emph{-Cia} changing from a transitivising suffix to a marker of passive voice (\citet{hale_1968, hohepa_1967, hohepa_1969, chung1978} and \citet{jonsson1998}). The Grambank dataset, however, (as many other typological surveys) only considers productive patterns and does not include information on specific formal expressions of grammatical phenomena or so called fossils which no longer participate in the function productively.

Surveys of this kind do not track forms, but abstract features such as ``Does the language mark passive voice?''. This means that two languages can be coded identically for entirely different reasons and without being related. For example, Koasati [koas1236] of Louisiana, USA, and Mokilese [moki1238] on Mwoakilloa in the Federated States of Micronesia are both coded as having a construction for predicative possession of the type ``Topic'' by \citet{wals-2011-117}. However, they belong to entirely different language families and different parts of the world. Their similarity does not necessarily imply shared inheritance. This is unlike cognacy data, where the fact that two languages have cognates in common is direct evidence of relatedness.

As an example of this difference, let's consider definite markers in Oceanic languages. \citet{crowley1985common} investigates ``common noun phrase markers''\footnote{This term is more or less identical to a pre-nominal definite/specific article.} in Oceanic and finds that in many languages there is a reflex of proto-Oceanic \emph{*na/*a}, but that in some languages there is another marker with a different origin (M\={a}ori \emph{te} for example). In Crowley's study, languages where there is no common noun phrase marking whatsoever and those with a marker which is not cognate with \emph{*na/*a} are both included in type 1 (see Fig.~\ref{fig:crowley_map}). These languages are contrasted with those that have retained some kind of reflex of \emph{*na/*a} (type 2-4 in Fig.~\ref{fig:crowley_map}). This means that we can distinguish languages which have retained the proto-form from those that have not, but not languages which have a common noun phrase marker from those that do not.

\begin{figure}
\centering
\includegraphics[width=8cm]{illustrations/crowley_1985_map.png}
\caption[Map of four different types of common noun phrase markers in Oceanic from Crowley(1985).]{\textbf{Map of four different types of common noun phrase markers in Oceanic from \citet[162]{crowley1985common}. Type 1: absence of common noun phrase marker or marker is not a reflex of \emph{*na /*a}, type 2: non-productive system involving a reflex of \emph{*na /*a}, type 3: productive marking involving \emph{*na /*a} as a prefix that is regularly separable from the noun and type 4: productive marking involving \emph{*na /*a} generally existing as a free-standing marker.}}
\label{fig:crowley_map}
\end{figure}

In contrast, the corresponding feature in Grambank is `GB022: \emph{Are there prenominal articles?'} (see Fig.~\ref{fig:gb022_map}). Languages that have \emph{te} (like M\={a}ori) or reflexes of \emph{*na/*a} as articles before the noun both count as ``yes'' (1) for GB022 and those that have no prenominal marker as a ``no'' (0). This Grambank feature splits Crowley's type 1 into two categories, and combines all the languages with reflexes of \emph{*na/*a} and \emph{te} (or other markers) into one category. We can now distinguish those that have a pre-nominal article from those that do not, but we cannot tell apart those which have retained the proto-form from those which have not. Since many reconstructions of grammar in historical linguistics rely on particular forms, this is an important difference. This does not matter for features such as word order.

\begin{figure}
\centering
\includegraphics[width=16cm]{illustrations/plots_from_R/coverage_plots/maps/map_GB022.png}
\caption{{Map of Austronesian languages for GB022 \emph{Are there prenominal articles?} Yellow = ``yes", purple = ``no".}}
\label{fig:gb022_map}
\end{figure}

The data in this study is composed of abstract features such as ``is a grammatical distinction made between X and Y?''. This makes it different from most studies of grammatical features in historical linguistics. As was noted earlier, it is possible for two languages to be coded alike but not share ancestry. It is also possible that such abstract features track something beyond the particular forms. \citet[503]{ross2004morphosyntactic} notes that a particular structure of the pronominal system of Mokilese is maintained, despite the formal markers being continuously replaced. He argues that there are discourse related reasons for maintaining this system and that the interaction between this construction and the rest of the grammar is such that the distinction is maintained. When particular markers are lost in this system, new ones appear in their place\footnote{He also notes that Goddard has observed similar patterns in Algonquian languages \citep{goddard1993algonquian}.}. This may be true of more features, and in such cases languages can share a grammatical feature but not have the same particular expression, and this could be due to inheritance. In addition, in many instances --- particularly within families --- abstract features such as 'GB022: \emph{Are there prenominal articles?}' are in fact correlated with specific forms even if the forms are not explicitly being tracked.

%Furthermore, it is possible that due to the interconnectedness of structural features related languages can develop similarily without 
%Related languages may also show similarity due to inheritance, even if the relevant state was not present in the ancestor, as the quote from \citet{chung1977aspects} earlier continues:

%\begin{quotation}
%\noindent\emph{[I]t is also reasonable that changes begun in a Proto-language may have continued even after its separation into daughter languages. In this way, related languages may come to share a feature which existed only in embryonic form, or not at all, in their common ancestor}\footnote{This idea is important to a particular hypothesis about Proto-Polynesian syntax, because according to \citet{chung1978} Proto-Polynesian was accusative and Tongan and S\={a}moan both developed ergativity semi-independently while the Eastern Polynesian languages (which are more closely related to S\={a}moan than to Tongan) did not develop this feature.}.
%\end{quotation}
%\begin{flushright} \citet[539]{chung1977aspects} \end{flushright}
%
%This theory proposes that the conditions for developing a certain feature may have been present in the ancestral language even if the feature itself is absent. It is therefore likely that the daughter languages would develop it even if they were isolated from each other, because they have inherited the prerequisites for developing the feature. This is similar to what is known in the literature on cultural evolution as ``preadaptation'' \citep{scott2010language}. One might say that the seed is sown already in the parent language, and that as a result its daughter languages will likely turn out a certain way.
%
%This ties in with the dependencies of features, insofar as dependencies are representations of features ``moving as a group'' through time. If some of these features are reliable ``early movers'', one could use them to predict certain developments in daughter languages. This theory aligns well with a view of language as a system where everything neatly fits (``La langue est \emph{un système où tout se tient}'' [language is systematic / a system where everything fits], Saussure \citep{koerner1997notes}). This is in contrast to the view by, among others, \citet[328]{bloomfield1933language} who stated that \emph{every word has its own history}. It is likely that systematic effects like these are more probable in structural data than in lexical data.
%
%However, in this analysis we are investigating each feature separately so it is not possible to derive information about features co-evolving. It is also difficult for the algorithm \emph{not} to reconstruct a certain state in the parent language, if the majority of daughter languages possess it. This is one instance where knowledge of plausible paths and profiles of languages from classical linguistics may contribute information that is, so far, not possible to retrieve using computational means.

%In summary, the comparative method of historical linguistics involves Maximum Parsimony coupled with information on plausibility. It is not possible in computational reconstruction to take plausibility into account since it has not been formalised. The kind of data typically used in reconstruction of grammar in historical linguistics concerns specific forms, whereas the data for this paper is structural features.

\section{Material and methods}
\subsection{Computational phylogenetic methods}
\label{sec:asr_methods}

In this study, we will be reconstructing the presence or absence of structural features in proto-languages of the Oceanic subgroup using Maximum Parsimony and Maximum Likelihood. This section gives a brief overview of the methods. Further technical details concerning the precise application can be found in the supplementary material \ref{supp:tech_details}. For an extensive comparison of different methods of ancestral state reconstruction and their advantages, see \citet{joy2016ancestral}.

As discussed earlier in section \ref{sec:ars:metod:hist}, \textbf{Maximum Parsimony} finds the set of ancestral states that result in the fewest number of changes between nodes. Maximum Parsimony is intuitively simple. We saw in the previous section an example of how it can play out in a small tree. While the principle of ``Maximum Parsimony'' is practised in traditional historical linguistics as a part of the Comparative Method, it should be noted that they rarely use the term \emph{per se}, but rather the description of ``fewest number of changes along the tree''.

Maximum Parsimony may be simple and intuitive, but it is not without its critics. Part of the critique is that it does not take into account branch lengths in the tree (the time between splitting events). Furthermore, Maximum Parsimony necessarily assumes that the solution that posits the slowest possible rate of change is also the most probable one. This is not necessarily a valid assumption; some features may evolve at a faster rate than Maximum Parsimony predicts. Both of these disadvantages are addressed in the second method we will be applying: Maximum Likelihood.

%The second method which will be applied in this study is that of \textbf{Maximum Likelihood}. 
Ancestral state reconstruction using \textbf{Maximum Likelihood} posits the most likely ancestral state distributions based on the overall probabilities given all the nodes in the tree and all branches. This approach does not assume that the slowest rate of change is the most probable one. If, for example, the distribution of values at the tips is very scattered, with sibling pairs frequently having different values, Maximum Likelihood will infer that the feature has a high rate of change and use that information when positing ancestral states as well. The Maximum Likelihood algorithm assigns probabilities of state changes and distributions based on branch lengths. A mutation along a shorter branch is given more weight in the likelihood calculations than if it occurred in a longer branch. Furthermore, reconstruction using Maximum Likelihood allows us to use a model of change where we do not assume that the rates for losses (1$\rightarrow$0) are equal to the rate of gains (0$\rightarrow$ 1). In this study, we use an ``All Rates are Different" (ARD) model, which allows for the rate of loss and gain to be different\footnote{
Similarly to the studies by \citet{carling2021reconstructing} and \citet{goldstein_2022}, rates cannot vary within the tree.}. 

It is not possible for the computational implementation of Maximum Parsimony to take into account branch lengths, nor can it assume anything but the slowest rate of change or posit different rates for losses and gains. It is however possible that the Comparative Method in historical linguistics estimates something similar when they take into account the ``plausibility of the changes posited'' and that this is picked up by the reconstruction by Maximum Likelihood. It is possible that scholars of historical linguistics take length of time into account, for example, or assume that a loss is more likely than a gain for a given feature. In this study, we compare Maximum Parsimony and Maximum Likelihood reconstructions to the Comparative Method. If the results from the Comparative Method are more similar to that of Maximum Likelihood, a potential explanation would be that the ``plausibility of changes posited'' is indeed operating along similar lines as Maximum Likelihood by taking branch length into account and assuming varying rates of change.

Finally, we will also compare the predictions of historical linguists with computational predictions based solely on which value is the most common in the daughter languages of a given proto-language --- entirely disregarding the tree structure\footnote{This is similar to the frequency heuristic described in \citet{goldstein_2022}.}. In the toy example in Fig. \ref{fig:clark_tree}, this approach would reconstruct that the root had feature value ``X''. Whether we prefer Maximum Parsimony, Maximal Likelihood or another approach to reconstruction, it should be the case that actually taking the tree structure into account is the sounder methodology. %We expect that both methods has a higher degree of concordance with the findings in historical linguistics compared to only counting which value is most common.

%The third method employed is \textbf{Stochastic Character mapping}. This method was proposed by \citet{huelsenbeck2003stochastic} and is an extension of an approach suggested by \citet{nielsen2002mapping}. 
 
\subsection{Calculation of similarity between predictions from the Comparative Method and computational approaches}
\label{result_calc_section}
We calculate the similarity of the predictions of historical linguists and computational means with two measures: concordance and F1-scores. Concordance is known as \textit{accuracy} in machine learning, but we wish to avoid the connotation that what is being measured is the accuracy of the reconstruction as regards real languages. Rather, concordance measures how closely the computational reconstruction matches historical linguists' reconstruction. It is measured as the number of agreements about grammatical features (i.e. Grambank binary questions) of predicted protolanguages, divided by the total number of grammatical features predicted. 

F1-scores are the harmonic mean of the precision and recall\footnote{Precision is True Positives divided by True Positives + False Positives, recall is True Positives divided by False Negatives + True Positives. F1-score = 2 * ((precision*recall) / (precision + recall)) \citep{van1979information}.} \citep[133]{van1979information}. It is important to note that F1-scores disregard the number of True Negatives entirely, which is relevant in our case since some of the features in proto-languages are predicted to be absent. For both measures, 0 is the worst possible score and 1 the best in terms of similarity to predictions by historical linguists. 

In a similar study of ancestral states of cognate classes, \citet{jager2018using} compared three different methods of ancestral state reconstruction for lexical data (cognate classes): Maximum Parsimony, Maximum Likelihood and Minimal Lateral Networks. They found that reconstructions using Maximum Likelihood performed the most like the predictions by historical linguists. However, \citet{jager2018using} describe the general performance of all the computational reconstruction methods they used as ``poor''.  \citet{jager2018using} evaluated the methods using the F1-score. The highest F1-score was 0.79 (Austronesian language sample, Maximum Likelihood), and the worst was 0.44 (Indo-European, Minimal Lateral Networks).

%In addition to these two scores we will also calculate how much better each method does compared to just counting which is the most common vale of a feature in the daughter languages. As we learned in section \ref{sec:ars:metod:hist}, simply relying on frequency and not taking the tree structure into account can lead us astray. Whether we prefer Maximum Parsimony, Maximal Likelihood or another approach to reconstruction it should be the case that actually taking the tree structure into account is the more sound methodology. We expect that both methods has a higher degree of concordance with the findings in historical linguistics compared to only counting which value is most common.

For each feature, the methods predict a distribution of the two states (presence and absence) for every ancestral node. If the distribution is majority presence (more than 60\% of the ancestral state is ``1'') it is registered in the results as ``Presence''; if less than 40\% presence it is registered as ``Absence''. If the ancestral state is between 40-60\% of either state, the prediction is registered as ``Half/Half''. This was done to highlight the amount of uncertainty the results sometimes contain, while at the same time making it a fair comparison between Maximum Parsimony and Maximum Likelihood. Comparing the raw distributions themselves is not a fair comparison because Maximum Parsimony is always more likely to suggest 0, 0.5 or 1 results whereas Maximum Likelihood rarely produces exactly 0 or 1. 

If the reconstruction of a feature by experts for that ancestral node was ``Presence'' and the algorithm did predict presence with over 60\%, it is counted as a ``True Positive'', and so on\footnote{The terms ``True'' and ``False'' are used here in accordance with terminology in machine learning. In this instance, they are indicating whether the results from the computational method and historical linguists agree. It should not be interpreted as a measure of ``Truth'' necessarily.}. Table~\ref{example_HL_prediction_table_true_positives} illustrates how the results are summarised.

\begin{table}[H]
\centering
\caption{Table illustrating how the results of ancestral node predictions are calculated.}
\label{example_HL_prediction_table_true_positives}
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
\textbf{Finding in historical linguistics} & \textbf{Prediction by Computational Method} & \textbf{Result} \\ \hline
Absence & >60\% Absence & True Negative \\ \hline
Absence & >60\% Presence & False Positive (type 1-error) \\ \hline
Presence & >60\% Presence & True Positive \\ \hline
Presence & >60\% Absence & False Negative (type 2-error) \\ \hline
Absence & 40-60\% Presence/Absence & Half \\ \hline
Presence & 40-60\% Presence/Absence & Half\\ \hline
\end{tabular}
\end{table}

For each method, a plain concordance score (Eq \eqref{eq:accuracy}) and F1-score (Eq. \eqref{eq:F1_score}) is then calculated.

\begin{equation}\label{eq:accuracy}
\frac{\text{True Negative + True Positive}}{\text{True Negative + True Positive + False Negative + False Positive}}
\end{equation}

\begin{equation}\label{eq:F1_score}
\frac{\text{True Positive} }
{\text{True Positive} + \frac{1}{2}\times(\text{False Positive} + \text{False Negative})}
\end{equation}

It is also important to take into account the Half-results. This count represents instances where the method was not able to say with a strong confidence that something was present or absent. The reason it is interesting to separate these out is that while they may indicate a majority result one way, it is not far from suggesting the direct opposite. For example, if one of the methods reconstructs Proto-Oceanic as having a 51\% chance of having ergative marking --- it is not far away from suggesting that this marking is absent. In order to take these type of cases into account the cut-off of 40\%-60\% was set and summarised as "Half" results. We can apply the concordance score and F1-scores to this summary statistic as well, as shown in Eqs. \eqref{eq:accuracy_incl_half} and \eqref{eq:F1_score_incl_half}. See supplementary material \ref{math_supp} for more details\footnote{I am very grateful for mathematical assistance from Stephen Mann.}.

\begin{equation}\label{eq:accuracy_incl_half}
\frac{\text{True Negative + True Positive} + \frac{\text{Half}}{2}}{\text{True Negative + True Positive + False Negative + False Positive + Half}}
\end{equation}

\begin{equation}\label{eq:F1_score_incl_half}
\frac{\text{True Positive} +  \frac{\text{Half}}{2}} 
{\text{True Positive} + \frac{1}{2}\times(\text{False Positive} + \text{False Negative}) + \text{Half}}
\end{equation}


All four scores will be reported, but we will rely mainly on the Concordance score with the inclusion of the Half-results. This is because this approach takes into account the True Negative (which F1-scores ignore) and it takes into account the possible uncertainty of the half-scores.


% mutate(F1_score = 2 * ((Precision*Recall)/(Precision + Recall)), 
  %         F1_score_incl_half = 2 * ((Precision_incl_half *Recall_incl_half)/(Precision_incl_half + %Recall_incl_half)) )%>% 
 


%In order to evaluate the results, we need to calculate a concordance score per method and tree. \citet{jager2018using} use the F1-score (harmonic mean between precision and recall) in their study of how computationally reconstructed lexical proto-forms compare to those reconstructed by historical linguists.  For example, if for a given proto-language there are 60 features reconstructed by experts and the algorithm result is 10 True Positives, 10 False Positives, 10 True Negatives, 10 False Negatives and 20 ``Half/Half'' then the F1-score is 0.5 (recall = 10 / (10+10) = 0.5, precision = 10 / (10+10) = 0.5 and F1-score = 2 *((0.5*0.5) / (0.5 + 0.5) = 0.5)). Note that the F1-score disregards True Negatives and Half /Half-results.

%F1-scores will be reported because they are insightful and have been used in similar studies. However, the F1-formula ignores the amount of True Negatives and Half/Half results. Therefore, in addition we will also calculate a simpler concordance score; how many concordant predictions did the algorithm make given all the predictions it made (aka ``accuracy'')? For example, if for a given proto-language there are 60 features predicted by experts with the same distribution of results as in the example above, then the concordance score would be (10 + 10)/40 = 0.5. We can also include the Half/Half-predictions, awarding 0.5 points for at least not strongly predicting a false value. In that case, this example has a concordance score of 0.5 ((10 + 10 + (20/2)) / 60). These scores all reflect different ways of assessing concordance and will give different perspectives on our results and how our algorithms are performing. %Features where there were more than half of the data-points missing in the tree were not to be included. hankfully there were no occurrences of this.

%\begin{equation} \label{accuracy_incl_half}
%\frac{\text{agree} + \frac{\text{half}}{2}}{\text{all reconstructions}}
%\end{equation}

\subsection{Data}

\subsubsection{The Grambank-dataset}
\label{asr:sec:GBcoverage}

The data for the study is taken from the Grambank-project \citep{grambankwebsite}. The Grambank dataset consists of 195 structural features which have been coded by a large group of research assistants for over 2,000 languages. This dataset includes 280 Oceanic languages. 

%The Grambank project is part of the Glottobank consortium, which is a collaboration between the Max Planck Institute for the Science of Human History in Jena (MPI-SHH), the Australian National University, the Australian Research Council's Centre of Excellence for the Dynamics of Language and the University of Auckland. The project is led by a team of senior linguists (Russell Gray, Simon Greenhill and Quentin Atkinson) and employs student assistants as coders in Kiel, London, Canberra, Uppsala and a few other locations. Coders who have been contributed significantly to the database are included as co-authors of the upcoming release paper \citep{grambank_release}, alongside other contributors. I have personally participated in this project as a coder and as a coordinator.

%The aim of Grambank is to provide a consistently coded set of structural features of the world's languages for research questions relating to history, complexity and more. The dataset will be published openly. 
 
%The Grambank dataset builds on previous typological work by \citet{dunnetal2005, dunn2008, reesinketal2009, dunnreesink2012} and \citet{ntswebsite}. The project has a global focus and the aim is to include all languages in the world that are described for their core grammatical structure. 

% In the work by Dunn, Reesink and colleagues, they were particularly focussed on languages of Oceania and Australia and the prehistory of migrations and contact there. The Nijmegen Typological Survey-project \citep{nts2014, ntswebsite} on the other hand was focussed on African languages.

The questionnaire's 195 questions cover what are often called the ``core domains'' of traditional grammatical description: word order, possession, negation, tense, aspect, mood, deixis, interrogation, comparatives and more. Features are included in the questionnaire if it is likely that it is possible to answer them for the majority of the world's languages which are at least described in a grammar sketch (approx 4,000 languages). This means that rarer features are not included. The full questionnaire is found in appendix \ref{Grambank_features}. 

The Grambank dataset is coded by student and research assistants under the supervision of expert linguists. Each feature is accompanied by documentation guiding coders so that the questionnaire is applied as consistently as possible across languages. For more details on the coding workflow of Grambank, see \citet{slingerland2020coding}. %For further details on the dataset, see Supplementary Material ~\ref{supp:dataset_details}.

%It is crucial in a cross-linguistic survey of this kind that the features are applied consistently across all languages of the sample. Within the Grambank-project, we strive towards a high level of consistency between coders. There are many coders employed and we have established work-flows to ensure that the features are applied consistently across languages. New coders are trained in the workflow and linguistic definitions through collaborative coding. Each feature in the questionnaire is accompanied by a helpful and pragmatic definition in a wiki-page. Each feature is also associated with a ``patron'', an expert linguist assigned to a set of features who has the final word should any further clarification be needed or disagreements arise. There are seven patrons in the project: Alena Witzlack-Makarevich, Harald Hammarström, Hannah Haynie, Jeremy Collins, Jay Latarche, Jakob Lesage and myself. All coders in the project are able to converse with each other and patrons through GitHub, an online platform for project coordination and code collaboration. When we are unable to make a coding decision with sufficient confidence, the data-point is marked as ``?''.


\subsubsection{Data coverage} 
This study is focussed on the Oceanic subgroup of the Austronesian language family. The Oceanic subgroup covers almost all languages in Remote Oceania (with the exceptions of Chamorro and Palauan) and large parts of Near Oceania. Fig.~\ref{Oceanic_map} from \citet[2]{protooceanicvol5} shows the extent of the major subgroups of the Austronesian language family, with Oceanic covering the largest surface area. Following the language classification of Glottolog 4.0 \citep{glottolog40}, there are 522 languages in total in the Oceanic subgroup.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{illustrations/ross_pawley_osmond_protooceanic_vol5.png}
\caption{{Map of the Austronesian language family and major subgroups, from \citet[2]{protooceanicvol5}.}}
\label{Oceanic_map}
\end{figure} 

Not all languages of the Oceanic subgroup have a grammatical description, but out of those that have it nearly all are included in Grambank. Table~\ref{GB_coverage_table_island_group} shows the coverage of Oceanic languages in the entire dataset. According to Glottolog, there are 289 Oceanic languages that have a grammar or grammar sketch which means that they can be included in Grambank at all. It is not always possible to fill in all the features for every language. Twenty of the Oceanic languages that are included to date are less than 50\% completed for Grambank questions. This can be due to lack of access to descriptive work, or that the content of the descriptive work does not cover the necessary domains in enough detail for the coders to answer enough questions. The map in Fig.~\ref{GB_austro_coverage} shows the same coverage information, with languages coded for their data coverage status.

\newpage
\input{"illustrations/plots_from_R/coverage_plots/tables/island_groups_table.tex"}
\newpage

\begin{sidewaysfigure}[H]
\centering
\includegraphics[width=\textwidth]{illustrations/plots_from_R/coverage_plots/maps/coverage_map_oceanic.png}
\caption{{Map of Oceania, with Oceanic languages coloured for their coverage in Grambank.}}
\label{GB_austro_coverage}
\end{sidewaysfigure} %#update

The coverage of Grambank data for the Oceanic subgroup is in general better in the east than in the west. However, since we control for genealogical relatedness through the distance control approach, this is less of a problem for our methodology than if we were using traditional probability sampling (c.f. \citet{ross2004morphosyntactic}).

\subsubsection{The trees}
\label{the_trees}
The tree phylogenies used in this study are: a) the Maximum Clade Credibility Tree (MCCT) from \citet{grayetal_2009}; b) a random sample of 100 posterior trees from the same source; c) the tree from Glottolog 4.0\footnote{The tree of Glottolog 4.0 \citep{glottolog40} is based on work by \citet{blust_2009, blust_2014} and \citet{blust_chen_2017}.}. 

Figure ~\ref{tree_coverage_oceanic_gray} and Figure ~\ref{tree_coverage_oceanic_glottolog} show the Grambank coverage of languages over the phylogenies from the Gray et al 2009-MCC-tree and the Glottolog-tree respectively. 

\begin{figure}[p]
\centering
\includegraphics[width=\textwidth]{illustrations/plots_from_R/coverage_plots/tree/Oceanic_tree_desc_status_gray_et_al_tree_mcct.png}
\caption{{Maximum Clade Credibility Tree of Oceanic from \citet{grayetal_2009}, with languages coloured for coverage in Grambank.}}
\label{tree_coverage_oceanic_gray}
\end{figure}

\begin{figure}[p]
\centering
\includegraphics[width=\textwidth]{illustrations/plots_from_R/coverage_plots/tree/Oceanic_tree_desc_status_glottolog_tree.png}
\caption{\textbf{Tree of Oceanic from Glottolog, with languages coloured for coverage in Grambank.}}
\label{tree_coverage_oceanic_glottolog}
\end{figure}

One of the major differences between the trees is that the Glottolog-tree does not contain \emph{any} information about branch lengths. All the branches in the Glottolog-tree are of the same length (1), whereas the branches in the Gray et al 2009-trees (the MCCT and the posteriors) have meaningful branch lengths based on rates of change in the underlying data (basic vocabulary) and calibration points (archaeological dates). This can be seen in the visualisations in Figures ~\ref{tree_coverage_oceanic_gray} and \ref{tree_coverage_oceanic_glottolog} where the first has varying lengths of branches but the latter all have a uniform length (1). This has the consequence that some tips in the Glottolog-tree are much further from the root than others. This is a big disadvantage with this type of tree, since it suggests that different amounts of time has passed between the root and the languages at the tips. Further technical details of the trees can be found in Supplementary Material ~\ref{supp:tree_details}.

The Glottolog-tree contains all the languages in the Oceanic subgroup. Therefore the coverage per island group that is summarised in table ~\ref{GB_coverage_table_island_group} in the previous section applies to the Glottolog-tree as well. However, the \cite{grayetal_2009}-trees do not contain all Oceanic languages, but rather 155. Out of these 132 also occur in the Grambank dataset. %A breakdown of coverage for the\cite{grayetal_2009}-trees per island group is found in table ~\ref{GB_coverage_table_island_group_gray}.

Finally, we are also using a sample of the posterior trees from \cite{grayetal_2009}. Their study yielded 4,200 posterior trees. Tree topologies that are more probable occur more often, but less probable trees also appear in the posterior. By using a set of possible trees instead of just one we can include other possible histories into our analysis, which could for example estimate contact events as well as inheritance. Figure ~\ref{densitree_plot} shows a visualisation of the 100 trees which are used in this study.

\begin{figure}[p]
\centering
\includegraphics[width=12cm]{illustrations/plots_from_R/coverage_plots/tree/gray_et_al_2009_100_sample_densitree.png}
\caption{\textbf{DensiTree \citep{bouckaert2014densitree} visualisation of the 100 random sampled trees from the Gray et al 2009-posterior.} Made with the function densiTree() from the R-pacakge Phangorn \citep{phangorn}.}
\label{densitree_plot}
\end{figure}

\subsubsection{Data from historical linguistics on Oceanic proto-language grammar}
\label{sec:POC_lit_review}

%The Oceanic subgroup is well-studied in historical linguistics, in particular its lexicon (see the book series on the Proto-Oceanic lexicon \citep{protooceanicvol1, protooceanicvol2, protooceanicvol3, protooceanicvol4, protooceanicvol5}, among other publications). There has also been considerable work done on reconstructing the grammar of proto-languages, in particular Proto-Polynesian. See table \ref{HL_prediction_table_summary} in section \ref{sec:POC_lit_review} for a summary of all the sources consulted from classical historical linguistics.

The proto-languages of the Oceanic subbranch of the Austronesian language family are generally well researched in terms of their lexicon and phonology (see the book series on the Proto-Oceanic lexicon \citep{protooceanicvol1, protooceanicvol2, protooceanicvol3, protooceanicvol4, protooceanicvol5}, among other publications). There is also substantial work done on the grammar of Proto-Oceanic using the comparative method. I have summarised several major works in the field and distilled their research into testable hypotheses given the Grambank data and our methods. This section gives an overview of the works included and examples of how they have been incorporated into the study. Table~\ref{HL_prediction_table_summary} lists the publications used for the reconstruction of proto-Oceanic by historical linguists. 

For each of these publications, findings have been extracted that support a certain state of a Grambank feature at a certain node. For example, \citet[4]{marck2000_encyclo} writes that a causative prefix has been reconstructed for Proto-Polynesian (\emph{*faka-}). In the Grambank questionnaire we have the feature GB155 `\emph{Are causatives formed by affixes or clitics on verbs?}'. For the ancestral node that connects all the Polynesian languages, we should expect that for GB155 the state is either wholly or overwhelmingly ``1'' (yes/presence). For simplicity, I have only considered four ancestral languages: Proto-Oceanic, Proto-Central Pacific, Proto-Polynesian and Proto-Eastern Polynesian. The choice to focus on these four in particular was based on the fact that they are the most well-researched proto-languages in the literature. 

%For example,  (an ancestral language of Rotuman and Fijian separately from  Polynesian, Samoan and Northern Outliers excluding Eastern Polynesian). 

The literature suggests that Proto-Oceanic was a language with a pre-nominal definite/specific article \citep[136]{crowley1985common}, a distinction between inclusive and exclusive first person pronouns (\citet[112]{pawley1973some}, \citet[184]{crowley1985common}, \citet[500]{ross2004morphosyntactic}, \citet[67, 75]{lynchrosscrowley_proto_grammar_oceanic}), no gender distinctions in pronouns \citep[498]{ross2004morphosyntactic}, a dual number category in pronouns (\citet[498]{ross2004morphosyntactic}, \citet[69]{lynchrosscrowley_proto_grammar_oceanic} and \citet[173]{pawley1973some}), a distinction between alienable and inalienable possession\footnote{A distinction can be made between three different kinds of possessive classification: alienable/inalienable, direct/indirect and dominant/inactive. For the purposes of Grambank and this study, these are treated as similar enough to be included into the same category.} \citep[69]{lynchrosscrowley_proto_grammar_oceanic}, prepositions (\citet[167]{pawley1973some}, \citet[498]{ross2004morphosyntactic}), subject proclitics and object enclitics on the verb (\citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic}), possessive suffixes on the possessed noun (\citet[495]{ross2004morphosyntactic}, \citet[155]{pawley1973some}) and a transitivising suffix on verbs (\citet[352]{pawley1970change}, \citet[171]{pawley1973some}, \citet[80, 92]{lynchrosscrowley_proto_grammar_oceanic}). The reconstructions regarding ergativity will be presented separately.

Most of the time, the scholars of Proto-Oceanic are in agreement in their predictions. For example, \citet[142]{pawley1973some}, \citet[292]{ross2007two}, \citet[xiii, 125]{clark1973aspects} and \citet[89]{lynchrosscrowley_proto_grammar_oceanic} all propose that the proto-language of the Polynesian subgroup had a construction marking prohibitive that was different from declarative negatives. However, in some instances there are disagreements. As discussed earlier, one such case is the alignment system of Proto-Polynesian. \citet{clark1973aspects} claims that the system was ergative while \citet{hale_1968}, \citet{hohepa_1967,hohepa_1969} and \citet{chung1978} argue that Proto-Polynesian was accusative and several of the daughter languages developed ergativity later. \citet{kikusawa2002proto} and \citet{ball2007ergativity} also disagree on the alignment of Proto-Central Pacific. Because of this disagreement, the results for the computational ancestral reconstruction for Grambank features regarding alignment of these two proto-languages are presented separately.

In the Grambank project, research assistants read published grammatical descriptions and extract information such that it fits with the definitions of our typological questionnaire (see Supplementary Material \ref{Grambank_features}). This survey of the literature on Proto-Oceanic grammar is essentially the same task. Just as with the literature on reconstructed languages, scholars sometimes disagree on the nature of contemporary languages and how they should best be analysed. It is up to the coder to make calls on which analysis to employ, what can be inferred from the literature and what should be left as unknown. It is possible to squeeze even more findings out of these publications; I have tended to be conservative in my interpretations. Out of the 201 (binarised) features in our questionnaire, 33\% (67) were answerable for Proto-Oceanic given this material. The average completion per language in the whole of the Grambank dataset is 75\%. 

\newpage
\section{Results}

\subsection{Concordance between traditional historical linguistics and computational methods}

We are examining results from three approaches in total: a) Maximum Parsimony, b) Maximum Likelihood and c) Most Common value in daughter languages. For (a) and (b) we are also using three different trees: i) Glottolog, ii) \citet{grayetal_2009} MCC-tree and ii) the mean values of reconstruction of a random selection of 100 (out of 4,200) trees in the Bayesian posterior of \citet{grayetal_2009}. That gives 2 * 3 + 1 results, i.e. 7.

%The match between languages in Grambank and the Gray et al-tree is 112, meaning that results with less than 56 tips are ignored.  %#update

All results have been calculated in \texttt{R} \citep{R} using the packages \texttt{castor} (Parsimony, \citet{louca2017efficient}), \texttt{phangorn} (Parsimony, \citet{phangorn}) and \texttt{corHMM} (Maximum Likelihood, \citet{corHMM}). The packages \texttt{ape} \citep{paradis2004ape}, \texttt{adephylo} \citep{jombart2017package}, phytools \citep{revell2012phytools} reshape2 \citep{wickham2020reshape2} \and tidyverse \citep{tidyverse13} were also used for data wrangling, analysis, summarising and visualising.

%The full table of all predictions (excluding those relating to conflicts) and all results per feature, tree and method can be found in table~\ref{asr_table_appendic} in appendix \ref{ASR_comparison_table}. 

Table \ref{True_post_results_table} shows the number of False, Positive and Half-results for each method and tree\footnote{There was one feature for the ML method and the Gray et al 2009-trees where the computation could not be carried out because all the languages had the same value. In such cases, the function used (corHMM from \citet{corHMM}) gives an error because it cannot compute the rates matrix.}. One of the most striking features in Table \ref{True_post_results_table} is the large amounts of Half-results in the Most common Method --- the method where we simply count directly what is most common in all daughters. This means that there were many instances where this approach, which we know to be unsound, would not confidently be able to predict a presence or absence.
 
\input{"illustrations/plots_from_R/results/table_false_pos_etc.tex"}

Given these counts, we can calculate the concordance and F1-scores (see section \ref{result_calc_section}). These are displayed in Fig \ref{barplot_facet_results}. A score of 1 means identical to the predictions of historical linguists and 0 means entirely dissimilar from it.

\begin{figure}[p]
\centering
\includegraphics[width=11cm]{illustrations/plots_from_R/results/barplot_facet_scores.png}
\caption{\textbf{Barplots of concordance and F1-scores of each method.} NB that the y-axis starts from 0.7.}
\label{barplot_facet_results}
\end{figure}

The inclusion of the half-results have the effect of evening out the differences between the performance of the different methods. The concordance scores (including half-results) and the F1-scores (including half-results) for each method are more similar to each other.

Compared to the F1-scores from the lexical reconstruction of \citet{jager2018using}, all of the methods achieved higher scores. In this study, only statements about ancestral languages that could be mapped to Grambank-features were included. It is  possible that the study by \citet{jager2018using} had a greater overlap between all the reconstructions made by historical linguists and the meanings that they had data for. In that case, it is possible that the features that were possible to map to Grambank data were also those that Oceanic historical linguists are the most confident about --- hence the higher scores.

The method that tends to perform most similarly to historical linguists is Parsimony + the Glottolog 4.0 tree. The Glottolog 4.0 tree has a big disadvantage; it has no branch lengths and the topology is composed of a combination and compromise from several different sources as opposed to a principled and systematic investigation of lexical data. Parts of the tree are suggested by different scholars, which means that different clades are not necessarily comparable. It does have an advantage as well, and that is the sheer number of languages it includes. The overlap between languages included in \citet{grayetal_2009} is lower than the overlap between the Glottolog 4.0 tree and Grambank. It is possible that it is this sheer number of tips that gives it a greater concordance with historical linguists' predictions. The results also suggests that it is likely that historical linguists, in these specific studies, do not necessarily take into account branch lengths. 

Overall however, the methods preform similarly. Where they vary the most is for the plain F1-score (i.e. without including half-results). While it is appropriate to report this score as it is common practice when assessing performance in this manner, it is probably the score that is the least relevant for this particular study object since it entirely ignores True Negative-counts. Given that, if we focus instead on the concordance score there is very little that tells apart the different methods ---- they are giving very similar results. The results for MP and ML for the random 100 posterior samples performs slightly better than the plain MCC-tree, which may indicate that they are possibly picking up some relevant history not represented in the MCC-tree, such as horizontal transfer.

%As was discussed earlier, there are several different ways of evaluating the performance of these approaches. If we consider how often they made a prediction that agreed with historical linguistics out of all the times they made a confident prediction (Accuracy score excl Half/Half), then ML. If we award half a point for Half/Half predictions, Parsimony does better. However, in both instances the numbers are very close to each other.

%We are comparing our computational reconstruction results to those predicted by expert linguists. The reason that the Glottolog tree is more in line with the predictions from historical linguistics is probably because it resembles the tree most historical linguists are used to more than the Gray et al-2009 tree does (the Glottolog tree is based on \citet{blust_2009,blust_2014} and \citet{blust_chen_2017}). That is not to say it is necessarily a better reflection of the true history of these languages, but rather that it may fit better with the underlying model that the field of historical linguistics has been working with in recent decades. Most of the literature on reconstructions of Proto-Oceanic does not include detailed accounts of the exact tree topologies and branch lengths used to reconstruct the ancestral languages. As was shown in section \ref{sec:asr_methods}, we had to impute branch lengths for the Glottolog-tree. The manner by which reconstructions are postulated in historical linguistics is typically by considering how well distributed the phenomena are over certain genealogical and areal subgroups. If the distribution is convincingly non-random and the comparative method can be used to reconstruct forms, predictions about the proto-language are made (c.f. \citet[109-110]{pawley1973some}).

%Furthermore, there were fewer matches between languages for which there is Grambank data and the Gray et al Tree, making for more uncertainty in predicting ancestral states.

%In a similar study, \citet{jager2018using} attempt to reconstruct cognate classes for the proto-languages of three different language families. They used various approaches: binarising versus not binarising data; Maximum Parsimony versus Maximum Likelihood Estimation versus Minimal Lateral Networks; and using a single consensus tree versus sampling several from the tree posterior. The highest F1-score they achieved in this paper was 0.79 for the Maxmimum Likelihood Estimation reconstruction of Austronesian (using either a single tree or a sample of trees). This means that all of our results above perform ``better''. While this may be pleasing, it is not yet entirely clear why this is. 

%e were also somehow easier to reconstruct, and if so that would explain the higher F1-scores.
%\label{sec:ars:metod:hist}

%Many of the features that have been reconstructed for proto-languages of the Oceanic subgroup are also very common among Oceanic languages. For example, in our dataset 223 languages have a distinction between alienable and inalienable possession, and three do not have this feature . It is perhaps no surprise that historical linguists, Maximum Parsimony and Maximum Likelihood  agree that it is likely that the proto-languages have this feature as well\footnote{There was one exception. Maximum Likelihood on the Glottolog tree did not confidently predict presence of alienablity possession for Proto-Oceanic, the result was classified as ``half''. It did however predict alienablity for Proto-Polynesian.}. However, it is not always so simple. If this was all there was to it, we could just use raw distributions to reconstruct features of proto-languages. Historical linguists stress the importance of Maximum Parsimony and plausibility in their reconstructions, and as we saw in Fig. \ref{fig:clark_tree} (section \ref{sec:ars:metod:hist}), raw distributions alone can be misleading --- it is essential to take into account the tree structure. For example, \citet[118]{pawley1973some} suggests that verb-final word orders may have been possible in proto-Oceanic. This is tracked by feature GB133 \emph{`Is a pragmatically unmarked constituent order verb-final for transitive clauses?'}, and most languages are marked as `no' for this feature. However, Maximum Likelihood and the Gray et al 2009-tree did reconstruct presence of this feature at the root. 108 of the tips of this tree were absent, and 7 present, and yet the result was presence for Proto-Oceanic. This is (partially) due to the particular tree structure, where the languages with this feature attach further up in the tree structure (see Fig. \ref{GB133_tree_ML_gray})\footnote{It should be noted that the Maximum Parsimony result for the same tree did not reconstruct presence at the root. This has to do with the way Maximum Likelihood takes into account the distribution across the tree in each reconstruction, which gives the ancestral node of Maleu-Kilenge [male1289] and Kove [kove1237] a higher change of presence than it would under Maximum Parsimony.}\textsuperscript{,}\footnote{The languages with a presence for this feature are also mostly on the island of New Guinea and it is possible that this is a result of contact with non-Austronesian languages, as anonymous examiner 3 kindly pointed out.}.

%\newpage
%\begin{figure}
%\centering
%%%\includegraphics[width=\textwidth]{illustrations/plots_from_R/ML_gray_-GB133.png}
%\caption[Ancestral state reconstruction on tree for feature GB133, Gray et al 2009-tree and Maximum Likelihood.]{\textbf{Ancestral state reconstruction on tree for feature GB133, Gray et al 2009-tree and Maximum Likelihood. Yellow = presence, purple = absence.)}}
%\label{GB133_tree_ML_gray}
%\end{figure}
%

%
%It is often as revealing to study where the results got it ``wrong'' as where it was ``right''.Table~\ref{ASR_comparison_worst_table} shows the results for the automatic reconstructions that agreed the least with findings from classical historical linguistics. 
%
%%The two parsimony sets of results did propose that Proto-Oceanic did not have tense marking bound to the verb (GB082-GB084), nor is it by an inflecting word (GB121). However, when it came to tense marking by a particle and the aspect and mood marking, the automatic reconstructions were among the most dis-concordant with the expert predictions out of the entire dataset. In the Grambank dataset, we make a distinction between TAM-markers bound to the verb and free-standing markers that inflect versus those that don't. One possible factor that could have contributed to this is that TAM-markers in Oceanic languages are often described as forming portmanteau markers with subject markers. However, there is variation in how authors of grammars express this in their publications, and possibly also how our coders interpret the situation. This requires further investigation, which is unfortunately outside the scope of this study.

\subsection{New predictions}
Besides the predictions made by historical linguists, we can also explore what else has strong support in our computational reconstructions that is not explicitly mentioned in the literature. There are 110 features that are predicted as present in the four proto-languages by the two methods with each tree(s) (Glottolog, Gray et al 2009 MCCT and ditto posteriors); i.e. 6 times. For example, that Proto-Oceanic has inclusory constructions, Proto-Central Pacific uses verbs for property attribution (``adjectives'') and Proto-Polynesian has numeral classifiers.  A full list of these are found in Supplementary Material \ref{asr_table_extra}.

Many of these are probably not surprising to most historical linguists working on Oceanic languages, but they were not explicitly predicted in the sources surveyed for this study.

%three out of the four sets of results predicted that the order of numeral and noun is N-Num, all tests supported that ``adjectives'' in Proto-Central Pacific behaved like verbs when used predicatively, and all tests also supported that Proto-Polynesian had three or more distance contrasts among demonstratives. 

\subsection{Where the conflicts are: Ergativity}
The nature of the alignment system of Proto-Polynesian and Proto-Central Pacific is contested. \citet{clark1973aspects} posits, primarily on the basis of Maximum Parsimony, that Proto-Polynesian was ergative whereas \citet{hale_1968}, \citet{hohepa_1967,hohepa_1969}, and \citet{chung1978} argue that it was accusative (while they suggest different historical pathways, they agree that Proto-Polynesian was nominative-accusative). 

Grambank has two features that pertain to these disagreements:

\begin{itemize}
\item GB408 \emph{Is there any accusative alignment of flagging?}
\item GB409 \emph{Is there any ergative alignment of flagging?}
\end{itemize}

It is entirely possible for a language to be entered into the database as ``yes'' for several of these, i.e., from the perspective of Grambank languages aren't ``ergative'' or ``accusative'' --- they can have both ergative and accusative flagging simultaneously. This makes it possible for us to prove both Chung and Clark ``right'', the results can come out such that Proto-Polynesian had both accusative \emph{and} ergative alignment flagging. However, the results in fact come out strongly in favour of the proposal by Clark. Table \ref{conflict_results_table} shows that MP, ML and MC all reconstruct presence for ergative flagging in Proto-Polynesian. On the matter of nominative-accusative marking, there is disagreement with the MP results all suggesting absence but the ML and MC giving a half-result.

\newcommand{\pb}[1]{\parbox[t][][t]{1\linewidth}{#1} \vspace{3.5pt}}
\input{"illustrations/plots_from_R/results/table_conflicts.tex"}

As was noted earlier, the computational reconstructions differ from those arrived at through the comparative method primarily because the data used in this study is abstract presence or absence of structural features whereas historical linguists use specific concrete forms instead (c.f. \citet{crowley1985common}). In the case of alignment systems, the matter of concrete markers is less of an issue. However, besides the parsimony principle (as laid out by \citet[19]{clark1973aspects} for example), expert historical linguists also take into account the plausibility of the proposed proto-language and the chain of changes posited \citep{chung1977aspects}. It is not possible for the computational reconstructions to take these assumptions into account without having them formally described and introduced into the model, which is not possible at this time. This may be the reason for the lack of support for Chung's theory; the crucial information that underpins it is not accounted for in this study.

Given the topology of the trees used in this study, where the ergative flagging language Tongan is always attached to the Proto-Polynesian root at a higher level than Eastern Polynesian languages, it is very likely that GB409 would be reconstructed as present for Proto-Polynesian. As Clark pointed out, it is the most parsimonious solution. However, it could still have been the case that GB408 (accusative) would have been reconstructed for Proto-Polynesian. The reasons for this may lie in different definitions of what counts as nominative-accusative or neutral in different descriptions, and/or in discussions of plausibility. As has been discussed earlier, it was not possible to include plausibility as a factor in this study.

The proposals of \citet{hale_1968}, \citet{hohepa_1967, hohepa_1969}, and \citet{chung1978} also involve reconstruction of passive voice that relate to the development of the ergative systems. They suggest different pathways by which languages can develop from a nominative-accusative system to an ergative-absolutive one that rely on changes in the specifics of the passive voice construction that we unfortunately do not track. Given our data, which simply records presence of a productive passive voice marker on the verb, we are not able to scrutinise the three precise theories in greater detail. The results largely support the hypothesis that Proto-Eastern Polynesian had a passive voice marker and that Proto-Oceanic and Proto-Polynesian did not. This can be seen as partial support for the proposals by \citet{hale_1968, hohepa_1967, hohepa_1969, chung1978}.

Concerning the alignment of Proto-Central Pacific, all the results, save the Most Common-model, predict an absence of ergative-marking. This is likely to be because Rotuman [rotu1241], Wester Fijian [west2519] and Fijian [fiji1243] are all coded as 0 for this feature and they split of early from the Proto-Central Pacific node. This supports the argument put forward by \citet{ball2007ergativity}. Similarity to the Polynesian case, given the tree structure it is difficult for the computational approaches to produce another result in lieu of more information on the particulars of the development of alignment systems or possible horizontal transfer.

\section{Conclusions}
In this paper, we have investigated the history of structural features of Oceanic languages to examine how computational reconstructive methods compare to reconstructions by historical linguists, including contributing to the debate on  alignment in Oceanic proto-languages.

We have found that computational reconstructions show a high degree of concordance with reconstructions from expert historical linguists. Reconstructions by both Maximum Parsimony and Maximum Likelihood agreed to a very large extent with the findings from historical linguistics. This suggests that the mechanisms at work in historical linguistic reconstruction are similar to the computational methods presented in this paper. This means that we have support for using conclusions regarding rate of change etc from the computational methods to estimate knowledge of historical linguists. This can aid us in making the implicit explicit. Whether or not the predictions from classical historical linguistics are correct or not is a different matter, which should be investigated by assessing the soundness of the principles at play and comparing with other evidence.

The results show that the methods which do not take into account branch lengths (Maximum Parsimony and Most Common) achieve a high concordance with historical linguistics predictions, and the Glottolog-tree typology performed slightly better than the \citet{grayetal_2009}-results for ML. This is potentially troubling since it seems a sound principle that branch lengths in trees matter. After all, an equal amount of time has past between the existence of a proto-community to today's extant languages. It is possible that some languages are more conservative than others and we should put ancient languages further back in the tree, but the differences in root to tip distances that a tree like Glottolog suggests (see Fig. \ref{tree_coverage_oceanic_glottolog}) seem extreme. The Comparative Method is well developed in terms of identifying cognates and sound correspondences, but the estimation of branch lengths has received less attention. This need not mean a return to glottochonology, this appears to be a misguided and overly simplistic approach \citep[371]{greenhill2015evolution}, there are other alternatives.

The future of research on the history of languages probably lies in the combination of human and computational labour. Computational endeavours of curating lexical cognate data \citep{list2022lexibank} and constructing trees \citep{grayetal_2009} still rely on teams of expert linguists annotating wordlists for cognacy. Methods are being developed for automatic cognate detection \citep{list2017potential}, but they are not yet ready to replace the vast human knowledge and experience of the experts of historical linguistics. However, once cognate classes, regular sound correspondences and structural features are identified the work then turns to subgrouping (constructing trees/networks) and reconstructing earlier states. For these tasks, there are suitable computational methods that can be applied (\citet{greenhill2015evolution}; \citet{gray_greenhill_defend_bayes}). These tasks can be greatly improved and effectivized by computational tools, which in turn can be given sensible priors and parameters to produce viable results.

In order to improve these methods, we could attempt to include the knowledge that historical linguists have about plausibility of changes, harmonics of traits and contact events.  Scholars of Oceanic languages have also acquired an immense knowledge of the languages, cultures and societies of the Pacific.  This is why their research is so valuable and trusted. It is no doubt difficult to convey all of this wealth of contextual information in each and every academic paper. However, in order for research to be more easily replicable by others and transparent, more of this knowledge should probably be formalised and/or put in print. Some or all of this kind of information can be incorporated to guide computational methods, for example as priors in models. They should not be given the power to entirely constrain the outcomes, but guide the conclusions the method reaches given the priors and data. In order for this to happen, even more information needs to be made explicit in historical linguistics studies.

The more information is made explicit in methodology the easier it is to assess the soundness of the study, replicate it and improve upon it. This study aims at increasing the transparency of both the principles of reconstruction in classical historical linguistics and the corresponding  computational approaches. Hopefully this study (alongside \citet{carling2021reconstructing} and \citet{goldstein_2022}) can be a starting point for more joint ventures into our grammatical past.

%In addition, we also need to encourage co-operation between traditional historical linguists and linguists applying new methods, as exemplified in this paper, when it comes to estimating branch lengths. Many trees proposed in classical studies of historical linguistics do not necessarily 

%One of the key pieces of information that is missing from this analysis is plausibility of changes and combinations of features.

%Within Oceanic historical linguistics, there exists a debate regarding the nature of the alignment system of Proto-Polynesian. The results of this study support the analysis that it was ergative. However, since the computational reconstructions are unable to take into account considerations of plausibility, which is the main difference between the different proposals, this cannot be taken as hard evidence. Further work in this area should seek to incorporate information about plausibility in order to increase the reliability of this result.

%explicit information on plausibility of rate of change and combinations of traits
%ways of estimating contact events
%models of history (trees/networks) with meaningful branch/edge lengths
%more training of computational methods to historical linguistics students
%more carefully coded data from HL to input to reasonable computational models


\newpage

\singlespacing
\bibliographystyle{bibtex_style_PhD}
\bibliography{ASR_Oceanic}
%\singlespacing


\newpage
\singlespacing
\appendix
\section*{Appendices}
\addcontentsline{toc}{section}{Appendices}
\renewcommand{\thesubsection}{\Alph{subsection}}

\subsection{Data availability}
\label{supp:data_avail}
The Grambank-dataset (version 1.0) will be published shortly and can be provided for anonymous reviewers under the condition that it is not shared before official publication. All code relevant to this paper will be published as a Git repository and how-ever the journal might want it published. The Git repository is private and is possible for reviewers to access under certain restrictions before publication.

\subsection{Technical details of methods}
\label{supp:tech_details}

For Maximum Parsimony, we are using the function \texttt{asr\_max\_parsimony()} from the R-package \texttt{castor} \citep{louca2017efficient} (which is an instantiation of the method described in \citet{sankoff1975minimal}) for calculating ancestral states and stability of features. This function produces ancestral states for all nodes and reports the number of changes that was minimally required for each feature. 

Ancestral state reconstruction using Maximum Likelihood Estimation involves computing each ancestral state from the tips up to the root taking into account branch lengths and the joint likelihood of states given all nodes in the tree \citep{wilks1938large, fisher1912absolute, pagel1994detecting, cunningham1998reconstructing}. The Maximum Likelihood Estimation function takes a set of observations and computes the parameter distribution that maximises the likelihood given the observed data\footnote{For a gentle introduction to the concept of Maximum Likelihood Estimation, see \citet{jonny_ML}.}. This means that for every split in the tree --- every ancestral node --- the Maximum Likelihood Estimation function computes what is the most likely distribution at that point given the nature of the entire tree. ML can be modified so that it allows for different rates of change. An Equal Rates (ER) model assumes that the chance of transition from state A to state B and from B to A are equal. However, we as linguists are aware that certain features are more likely to be lost than gained so this is not a reasonable assumption. Therefore, we allow the model to estimate different transition rates for going from A to B and from B to A given the data. This is known as ``All Rates are Different'' (ARD).

When estimating ancestral states with ML, it is possible to either a) find the state at each node that maximises the likelihood (integrating over all other states at all nodes, in proportion to their probability) at that particular node (marginal reconstruction), or b) find the set of character states at all nodes that (jointly) maximize the likelihood of the entire tree (joint reconstruction). We are using marginal reconstruction in this study since it is the recommended way to deal with uncertainty in reconstruction \citep{revell_2014}. These two methods often yield similar results, but can differ, see \citet[259-260]{felsenstein2004inferring},  \citet[121-126]{yang2006computational} and \citet[5]{joy2016ancestral} for more details. For our data, a trial run of joint reconstruction did not generate drastically different outcomes.

For this study, the function \texttt{corHMM} from the \texttt{R}-package \texttt{corHMM} \citep{corHMM} is used for marginal reconstruction of ancestral states and rates of change per feature. %Missing data in Grambank for languages included in the analysis was converted to ambiguous, (i.e ? in Grambank $\rightarrow$ 0\&1 for rayDISC()). 

%For the analysis of conservatism per language, the function \texttt{optim.pml()} from \texttt{Phangorn} \citep{phangorn} was used. This function rescales the branches in accordance with the Maximum Likelihood Estimation of change along them. The process of re-scaling the tree in this manner unroots the tree; instead of having root, branches and tips, it becomes an acyclic graph of tips connected by lines of appropriate length. Unrooted trees can be re-rooted using midpoting rooting, outgroup rooting or other methods\footnote{For a visual introduction to outgroup rooting, see \href{this blogpost}{https://phylobotanist.blogspot.com/2015/01/how-to-root-phylogenetic-tree-outgroup.html} by PhyloBotanist.}. For this study, the trees were re-rooted using Nanggu [nang1262], Ayiwoo [ayiw1239] or Natügu [natu1246] as an outgroup. As with the Maximum Parsimony analysis, the distance from the root to each tip was carried out with \texttt{distTip} and the distances were rescaled to between 0 and 1. 

Languages with missing data were pruned away in all analysis, no hidden state reconstruction of values at tips was preformed. The match between Glottolog and Grambank is 226, the match between \citet{grayetal_2009} and Grambank is 112. For the parsimony analysis of each feature, languages with missing data were dropped from the trees in the analysis for that feature. Features which could only be assigned values for less than half of the languages in the tree were excluded from the analysis.

For both Maximum Parsimony and Maximum Likelihood it is possible for a structural feature to appear and disappear several times along a lineage. This is different from cognate data where a cognate class cannot re-appear.

\subsection{Technical details on D-estimation}
\label{SM_d_estimate}
%D-estimates are a tool for measuring phylogenetic signal in a set of binary data. The method was proposed by Fritz and Purvis (2010) and is implemented in the R-package caper by Fritz and Orome. It’s fast, it’s neat and very useful. (Note: it measures phylogenetic signal not conservativness/stability.) I’ve noticed something that can be an issue, and that’s good to know about if you are using this method.
%
%Caveat: I could be wrong about what is going on here, this is what I think based on my understanding.
%
%The input is a set of binary data linked to a tree, and the output is a value - the D-estimate. If this value is 1 or higher, your data is similar to what would happen if the traits were randomly generated and if it’s 0 they’re more similar to Brownian evolution. You should also look at the p-values (pval0 and pval1) that the function outputs, as these take into account sample size and tells you how similar your set is to 0 or 1 given that. Values can also be lower than 0 and higher than 1. In my experience, values lower than -7 and higher than 7 are very rare and probably require closer scrutiny.
%
%I’ve noticed that sometimes the D-estimate can get much, much larger than 1 and much, much lower than 0. This occurs when the data you have is extremely skewed, for example when all but one tip is of the same value (all tips are 1 except one that is 0). I’ve created an example in an R-script to illustrate and I have suggestions for solutions.
%
%The tree below has 155 tips. 154 of those have a 0 for our binary trait, and one tip has the value 1. In cases like this, the D-estimate algorithm will severely struggle. It’s suggested D-estimates of 1520 once when it was run, and -21 another time. These are VERY different outcomes. What is going on?
%
%image
%Each time you measure D-estimate, a set of random value distributions are created and one Brownian simulation is carried out. This is why you get different D-estimates every-time you run it (unless you set random seed).
%
%The default number of random permutations for caper::phylo.d() is 1000. In cases where there is only one tip of one state, it just so happens that the random distributions sometimes hit very close to that. The random distributions are less likely to be similar to a more complicated pattern with more tips of either state.
%
%To illustrate this further, I used the tree above and a couple of different distributions of feature states.
%
%only one tip of state 0, either almost directly daughter of root, smack in the middle or random position
%sister pairs of same state, all other different
%two random tips of same state
%triplets of same states
%three random tips of same state
%quadruplets of same state
%four random tips of same state
%one larger clade of 31 tips of same state
%31 random tips of same state
%R-script here
%
%You can see the distribution of these simulated variables below:
%
%image
%I then run the D-estimate algorithm on this tree and these traits 8 times each and with different number of random permutations (1000, 20000 and 30000). This generates 408 D-estimates.
%
%The plot below shows on the x-axis the number of features that are of the minority state (i.e. 1 tip with value 0, 2 tips with value 0 etc) and the y-axis is the D-estimate value. The three panels represent the different permutation values.
%
%image
%While it is true that the D-estimate values for 1 tip only in one state are stilly varying a lot more than those with 2 etc - this seems to be improved with an increased number of permutations. The amount of variation in the output goes down as the number of permutation goes up, it gets a better sense of what was just a chance random similarity and what is more likely.
%
%Even when you set the number of permutations to 3000, the variation for cases where there is only one singleton tip is still pretty high (579 in my example), and the variance is also quite high for the cases of 2 and 4 cases compared to the case where a larger cluster exists.
%
%image
%If you want to dig deeper, there are also systematic differences if the singleton value is in a more or less direct daughter to the root (“outlier” in my code), smack in the middle or at a random position. It has to do with the way it does ancestral state reconstruction, which is through Felsenstein’s contrasting algorithm (sort of like max parsimony but smarter because it cares about branch lengths).
%
%The R-code I’ve uploaded doesn’t require you to download any data or anything, the tree and data are all there directly in the script. It doesn’t take that long time to run, and when it’s done it’ll do a little “pling!”. You can easily try it out and poke around yourself in the resulting data-frame.
%
%Solution
%
%If you are getting D-estimates that are varying wildly, first take a close look at your feature value distributions. Consider increasing the number of permutations to reign it in a bit.
%
%However, there’s something fundamental you need to consider if you’ve got very skewed data: in order for the D-measure to work, it needs groups of tips to latch onto, clumps. One tip is not a group. Two tips is better, but still a bit sus. You may want to disregard the D-estimates in such cases entirely, and separate those instances out in your data and compare and summarised them in a different way. Set them aside in one bucket and present them in some other way, and compare D-estimates of features that are more suited for this kind of analysis. Have a think about it, have a poke around - run the D-estimate many times and have a look at the variance you get.
%
%Good luck!
%
%P.S. Big thanks to my wonderfully smart husband Stephen (left below) for helping me work out the mathematics of all of this. He is a kind and intelligent person.

\subsection{Mathematics of the F1-score including half-results}
\label{math_supp}

I am very grateful for the assistance of Stephen Mann in working out the mathematics of these scores as they incorporate the Half-results.

\subsubsection{Standard definitions}\label{sec:standard}

The F1-score is the harmonic mean of precision and recall \citep{van1979information}.

\begin{align*}
    F_1 &= 2\times\frac{\text{precision}\times\text{recall}}
            {\text{precision} + \text{recall}}\\
        &= \frac{\text{TP}}
            {\text{TP}+\frac{1}{2}\times(\text{FP}+\text{FN})}
\end{align*}

\begin{align*}
    \text{precision} 
        &= \frac{\text{TP}}
            {\text{TP}+\text{FP}}
\end{align*}

\begin{align*}
    \text{recall} 
        &= \frac{\text{TP}}
            {\text{TP}+\text{FN}}
\end{align*}

%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
\subsubsection{Half-result definitions of precision and recall}\label{sec:halfsies}

The half-result-definitions of precision and recall add one half of the half-counts to the numerator, and all of the half-counts to the denominator:

\begin{equation*}
    \text{precision}_{\text{half}} 
        = \frac{\text{TP}+\frac{\text{H}}{2}}
            {\text{TP}+\text{FP}+\text{H}}
\end{equation*}

\begin{equation*}
    \text{recall}_{\text{half}}
        = \frac{\text{TP}+\frac{\text{H}}{2}}
            {\text{TP}+\text{FN}+\text{H}}
\end{equation*}

%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
\subsubsection{The question}\label{sec:question}

We want to define $F_{1,\text{half}}$.
A natural way to do it would be to follow the rule defined above, i.e.

\begin{equation*}
    F_{1,\text{half?}} = \frac{\text{TP}+\frac{\text{H}}{2}}
            {\text{TP}+\frac{1}{2}\times(\text{FP}+\text{FN}) + \text{H}}
\end{equation*}

\noindent However, we want to ensure $F_{1,\text{half}}$ has the same relationship with $\text{precision}_{\text{half}}$ and $\text{recall}_{\text{half}}$ as $F_1$ has with precision and recall.
So we need to determine whether the following equation is true:

\begin{equation}\label{eq:question}
    2\times\frac{\text{precision}_{\text{half}}\times\text{recall}_{\text{half}}}
            {\text{precision}_{\text{half}} + \text{recall}_{\text{half}}}
    \stackrel{?}{=}
    \frac{\text{TP}+\frac{\text{H}}{2}}
            {\text{TP}+\frac{1}{2}\times(\text{FP}+\text{FN}) + \text{H}}
\end{equation}

%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
%%%%%%%%%%%
\subsubsection{The proof}\label{sec:proof}

We will expand the left-hand side of \eqref{eq:question} and show it is equal to the right-hand side.
Let's forget about the $2\times$ for now (we will reintroduce it at the end).
Expanding the numerator gives:

\begin{equation*}
    \frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)}
    {\left(
        \text{TP} + \text{FP} + \text{H}
    \right)\left(
        \text{TP} + \text{FN} + \text{H}
    \right)}
\end{equation*}

\noindent Expanding the denominator gives:

\begin{align*}
    &\frac{\text{TP}+\frac{\text{H}}{2}}
    {\text{TP}+\text{FP}+\text{H}}
    +
    \frac{\text{TP}+\frac{\text{H}}{2}}
    {\text{TP}+\text{FN}+\text{H}}\\[1.5ex]
    &=
    %% Second line, left part
    %% Numerator
    \frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        \text{TP}+\text{FN}+\text{H}
    \right)}
    %% Denominator
    {\left(
        \text{TP}+\text{FP}+\text{H}
    \right)\left(
        \text{TP}+\text{FN}+\text{H}
    \right)}
    +
    %% Second line, right part
    %% Numerator
    \frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        \text{TP}+\text{FP}+\text{H}
    \right)}
    %% Denominator
    {\left(
        \text{TP}+\text{FN}+\text{H}
    \right)\left(
        \text{TP}+\text{FP}+\text{H}
    \right)}\\[1.5ex]
    %% Third line
    &=\frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        2\times\text{TP} + \text{FP} + \text{FN} + 2\times\text{H}
    \right)}
    {\left(
        \text{TP}+\text{FP}+\text{H}
    \right)\left(
        \text{TP}+\text{FN}+\text{H}
    \right)}
\end{align*}

\noindent When we put the numerator back on top of the denominator, both of their respective denominators cancel out, because they are both $(\text{TP}+\text{FP}+\text{H})(\text{TP}+\text{FN}+\text{H})$.
So we end up with \emph{the numerator of the numerator} on top of \emph{the numerator of the denominator}, like so:

\begin{align*}
    &\frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)}
    {\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)\left(
        2\times\text{TP} + \text{FP} + \text{FN} + 2\times\text{H}
    \right)}\\[1.5ex]
    &=
    \frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)}
    {2\times\text{TP} + \text{FP} + \text{FN} + 2\times\text{H}}
\end{align*}

\noindent Finally, we bring back the $2\times$ from the beginning:

\begin{align*}
    &2\times\frac{\left(
        \text{TP}+\frac{\text{H}}{2}
    \right)}
    {2\times\text{TP} + \text{FP} + \text{FN} + 2\times\text{H}}\\[1ex]
    &=
    \frac{\text{TP}+\frac{\text{H}}{2}}
    {\text{TP} + \frac{1}{2}\times(\text{FP} + \text{FN}) + \text{H}}
\end{align*}

\noindent And we have our suggested definition of $F_{1,\text{half}}$ as required.

\subsection{Binarisation of the Grambank features}
\label{supp:dataset_details}
Most of the feature questions are binary (GB027: Are nominal conjunction and comitative expressed by different elements?) but a few are multi-state (GB024 What is the order of numeral and noun in the NP? 1) Num-N, 2) N-Num, 3) both). For the analysis in this study, the multi-state features have been binarised. This is because the values of the multi-state features are not independent of each other; they all contain the value ``Both''. The value ``Num-N'' (numeral before noun) of GB024 is more similar to ``Both'' than it is to the other alternative ``N-Num''. The relationship between the three values are not equal or independent. The table in \ref{Grambank_features} contains a list of all the features used in this study, including the binarised features. The binarization results in a total of 201 features. 

\newpage
\subsection{Grambank features}
\label{Grambank_features}

\singlespacing
\begin{landscape}
\input{"illustrations/plots_from_R/results/GB_features_supp_table.tex"}
\end{landscape}
\newpage


\subsection{Further details on the tree phylogeny}
\label{supp:tree_details}

The tree from \citet{grayetal_2009} contains duplicates (see for example Nakanai). This is because it is a tree of word-lists for languages (doculects) rather than languages themselves. There are also some instances where multiple dialects of one language is included. For the analysis, only one tip per language was retained, based on which had best coverage in the underlying data for the tree (i.e. the Austronesian Basic Vocabulary Database, ABVD \citep{ABVD}). This means that duplicate languages were reduced to one, and only one dialect per language retained if there was more than one. 

For both Maximum Parsimony and Maximum Likelihood the tree were first pruned down to only languages where there is data in Grambank. For the further Maximum Parsimony analysis, tips representing languages where the data for a particular feature was missing were dropped for the analysis of that feature. For the Maximum Likelihood analysis, the value at such tips was converted to ambiguous. This is necessary because otherwise the rate of change across the different features would not be comparable in the Maximum Likelihood analysis.

\subsection{Further details on the Grambank coding of proto-languages }
\label{supp:proto_lg_coding}
Another example of how information in the publications was turned into Grambank feature coding relates to verbal markers encoding subjects and objects, as proposed by \citet{lynchrosscrowley_proto_grammar_oceanic} among others. In their book, there is a paper on reconstructions of grammar for Proto-Oceanic and in the section on the basic verb phrase we find the statement below:

\begin{quotation}
\noindent\emph{Attached to the verb root were a subject proclitic and, if the verb had a non-generic object, an object enclitic.} \end{quotation} \begin{flushright} \citet[83]{lynchrosscrowley_proto_grammar_oceanic} \end{flushright}

This statement, together with a verb schema provided in the section, support the notion that Proto-Oceanic had subject proclitics and object enclitics. We can also infer from this publication as a whole that the authors believe Proto-Oceanic in fact did \emph{not} have subject \emph{en}clitics and object \emph{pro}clitics. This second prediction relies on absence of evidence and is less strong than the first, but given that the whole paper is void of any description of object proclitics or subject enclitics being a possibility (including the verb schema) and argument structure is well-discussed, we may dare to make this leap. This information can be translated into the Grambank questionnaire by positing absence and presence for the six relevant features that concern argument marking on the verb (where S stands for subject of intransitive, A for subject of transitive and O for object; see table~\ref{example_HL_prediction_table}).

\begin{table}[H] %one of ste's favourite tables
\centering
\caption{Example of predictions from historical linguistics as rendered in Grambank features.}
\label{example_HL_prediction_table}
\begin{tabular}{|l| p{3cm}|  p{3cm}| p{3cm} | p{3cm} |}
\hline
\textbf{Grambank ID} & \textbf{Question} & \textbf{Proto-language} & \textbf{Expert prediction}& \textbf{Reference} \\ \hline
GB089  &Can the S argument be indexed by a suffix/enclitic on the verb in the simple main clause? &Proto-Oceanic &Absent & \citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic} \\ \hline
GB090 &Can the S argument be indexed by a prefix/proclitic on the verb in the simple main clause? &Proto-Oceanic &Present &\citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic}  \\ \hline
GB091 &Can the A argument be indexed by a suffix/enclitic on the verb in the simple main clause? &Proto-Oceanic &Absent &\citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic} \\ \hline
GB092  &Can the A argument be indexed by a prefix/proclitic on the verb in the simple main clause? &Proto-Oceanic &Present &\citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic}  \\ \hline
GB093  &Can the P argument be indexed by a suffix/enclitic on the verb in the simple main clause? &Proto-Oceanic &Present &\citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic} \\ \hline
GB094  &Can the P argument be indexed by a prefix/proclitic on the verb in the simple main clause? &Proto-Oceanic &Absent & \citet[498-499]{ross2004morphosyntactic}, \citet[83]{lynchrosscrowley_proto_grammar_oceanic} \\ \hline
\end{tabular}
\end{table}

\subsection{Table of historical linguistics sources surveyed}
\label{supp:proto_lg_coding_table}

\begin{longtable}{|p{3cm}|  p{5cm}| p{4cm} | p{3cm}  | p{3cm} |}
\caption{{Table of historical linguistics publications used in this dissertation for Proto-Oceanic grammar}}
\label{HL_prediction_table_summary} \\
\hline
\textbf{Citation}  & \textbf{Title} & \textbf{Proto-Languages}  & \textbf{Domains} \\ \hline
\endfirsthead

\hline
\textbf{Citation}  & \textbf{Title} & \textbf{Proto-Languages}  & \textbf{Domains} \\ \hline
\endhead


\citet{pawley1970change} & Grammatical reconstruction and change on Polynesia and Fiji & Proto-Central Pacific  &Verbal markers and aspect particles \\ \hline

\citet{pawley1973some} & Some problems in Proto-Oceanic & Proto-Oceanic and Proto-Polynesian  & Possession, noun phrase marking, negation, verbal markers, clusivity, word order  \\ \hline

\citet{clark1973aspects} & Aspects of Proto-Polynesian syntax & Proto-Oceanic and Proto-Polynesian  & Alignment, negation, word order, possession, noun phrase marking, voice \\ \hline

\citet{chung1978}  & Case marking and grammatical relations in Polynesian languages & Proto-Polynesian  & Alignment, word order, voice, noun phrase marking \\ \hline

\citet{crowley1985common}  & Common noun phrase marking in Proto-Oceanic & Proto-Oceanic &  noun phrase marking, clusivity  \\ \hline

\citet{jonsson1998} & Det polynesiska verbmorfemet \emph{-Cia}; om dess funktion i Samoanska & Proto-Polynesian & Verbal marker \\ \hline

\citet{marck2000_encyclo} & Polynesian languages (in Facts About the World's Languages: An encyclopaedia of the world's major languages, past and present)& Proto-Central Pacific and Proto-Polynesian & Word order, verbal markers, possession, clusivity \\ \hline

\citet{evans2003study} & A study of valency-changing devices in Proto Oceanic & Proto-Oceanic & Verbal markers \\ \hline

\citet{ball2007ergativity} & On ergativity and accusativity in Proto-Polynesian and proto-Central Pacific&Proto-Polynesian & Alignment, voice \\ \hline

\citet{kikusawa2001rotuman} & Rotuman and Fijian case-marking strategies and their historical development  & Proto-Oceanic & Possession, pronominal number \\ \hline

\citet{kikusawa2002proto}  & Proto Central Pacific ergativity: Its reconstruction and development in the Fijian, Rotuman and Polynesian languages & Proto-Central Pacific   & Alignment, word order \\ \hline

\citet{lynchrosscrowley_proto_grammar_oceanic} & The Oceanic Languages, paper 4: Proto-Oceanic & Proto-Oceanic, Proto-Central Pacific and Proto-Polynesian & Negation, word order, verbal markers, clusivity, possession, pronominal number, polar interrogation, nominalisations and more \\ \hline

\citet{ross2004morphosyntactic}\footnote{This paper makes statements about ``canonical'' Oceanic languages, which is technically different from \emph{reconstruction} of Proto-Oceanic. However, the author does state that the ``canonic type is probably also a reflection of the morphosyntax of Proto Oceanic'' \citep[492]{ross2004morphosyntactic} and has given personal approval for the paper to be included in this study in this manner.}  & The morphosyntactic typology of Oceanic languages &  Proto-Oceanic and Proto-Polynesian  & alignment, word order, verbal markers, possession, noun phrase marking \\ \hline
\end{longtable}


\subsection{Table of new predictions}
\label{asr_table_extra}
\singlespacing
\begin{landscape}
\input{"illustrations/plots_from_R/results/extra_predictions.tex"}
\end{landscape}


\end{document}
